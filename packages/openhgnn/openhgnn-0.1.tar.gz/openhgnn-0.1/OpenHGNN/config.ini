
[NSHE]
learning_rate = 0.001
weight_decay = 0.00001
beta = 0.05
seed = 0
norm_emd_flag = True

project_dim=128
context_dim=64
emd_dim=128

num_e_neg = 1
num_ns_neg = 4
max_epoch = 500
patience = 10

optimizer = adam
mini_batch_flag = False
[GTN]
learning_rate = 0.005
weight_decay = 0.001

hidden_dim = 64
out_dim = 16
num_channels = 2
num_layers = 2

seed = 0
max_epoch = 50
patience = 10

identity = True
norm_emd_flag = True
adaptive_lr_flag = True
mini_batch_flag = False

[RSHN]
learning_rate = 0.01
weight_decay = 5e-5
dropout = 0.6

seed = 1233
hidden_dim = 16
max_epoch = 500
rw_len = 4
batch_size = 5000
num_node_layer = 2
num_edge_layer = 2
patience = 20
validation = True
mini_batch_flag = False

[RGCN]
learning_rate = 0.1
weight_decay = 0.0001
dropout = 0.2

seed =0
hidden_dim = 32
out_dim = 32
n_bases = 40
n_layers = 3

max_epoch = 50
patience = 50
batch_size = 126
fanout = 4

validation = True
use_self_loop = False
mini_batch_flag = False

[CompGCN]
learning_rate = 0.01
weight_decay = 0.0001
dropout = 0.2

seed = 0
n_layers = 2
h_dim = 32
out_dim = 32
;We restrict the number of hidden units to 32. from paper

max_epoch = 500
patience = 100

comp_fn = sub
validation = True
mini_batch_flag = False

[HetGNN]
seed = 0
learning_rate = 0.001
weight_decay = 0.00001

dim = 128
max_epoch = 500
batch_size = 64
window_size = 5
num_workers = 8
batches_per_epoch = 50

rw_length = 50
rw_walks = 10
rwr_prob = 0.5

patience = 20
mini_batch_flag = True

[Metapath2vec]
learning_rate = 0.01
weight_decay = 0.0001
dim = 128
max_epoch = 100
batch_size = 32
window_size = 5
num_workers = 8
batches_per_epoch = 20

rw_length = 100
rw_walks = 50
rwr_prob = 0.5

seed = 0
patience = 100
mini_batch_flag = True

[HAN]
seed = 0
learning_rate = 0.01
weight_decay = 0.0001
dropout = 0.2

hidden_dim = 64
out_dim = 16
num_heads = 4-4-4
max_epoch = 500
patience = 40
mini_batch_flag = False

[MAGNN]
seed = 0
learning_rate = 0.005
weight_decay = 0.001 
dropout = 0.5 

hidden_dim = 64
out_dim = 3 
			 
inter_attn_feats = 128 
num_heads = 8 
num_layers = 2 

max_epoch = 100
patience = 30
mini_batch_flag = False
encoder_type = RotateE

[MAGNN_AC]
seed = 0
learning_rate = 0.005
weight_decay = 0.001 
dropout = 0.5 

feats_drop_rate = 0.3
attn_vec_dim = 64
feats_opt = 111
loss_lambda = 0.2
src_node_type = 0

hidden_dim = 64
out_dim = 3 
			 
inter_attn_feats = 128 
num_heads = 8 
num_layers = 2 

max_epoch = 100
patience = 30
mini_batch_flag = False
encoder_type = RotateE

[HGT]
seed = 0
learning_rate = 0.01
weight_decay = 0.0001
dropout = 0.4

batch_size = 5120
patience =40
in_dim = 32
hidden_dim = 64
out_dim = 16
n_layers = 2
num_heads = 2
num_workers = 64
max_epoch = 200
mini_batch_flag = True