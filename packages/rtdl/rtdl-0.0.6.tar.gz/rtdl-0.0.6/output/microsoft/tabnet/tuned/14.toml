seed = 14

[data]
normalization = 'quantile_normal'
path = 'data/microsoft'
y_policy = 'mean_std'

[model]
batch_momentum = 0.95
feature_dim = 64
num_decision_steps = 8
relaxation_factor = 1.563880969089764
virtual_batch_size = 512

[training]
batch_size = 16384
display_steps = 100
epochs = 50000
grad_thresh = 2000.0
patience = 16
sparsity_loss_weight = 1.479692699969368e-05

    [training.schedule]
    decay_rate = 0.7703369252398359
    decay_steps = 2000
    learning_rate = 0.00422820765879952
