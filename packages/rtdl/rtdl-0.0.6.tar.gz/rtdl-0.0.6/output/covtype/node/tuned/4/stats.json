{
    "dataset": "covtype",
    "algorithm": "node",
    "config": {
        "data": {
            "normalization": "quantile_normal",
            "path": "data/covtype"
        },
        "model": {
            "bin_function": "entmoid15",
            "choice_function": "entmax15",
            "depth": 6,
            "layer_dim": 128,
            "num_layers": 8,
            "tree_dim": 7
        },
        "seed": 4,
        "training": {
            "eval_batch_size": 8192,
            "lr": 0.001,
            "lr_n_decays": 0,
            "n_epochs": 1000000000,
            "optimizer": "adam",
            "patience": 16,
            "weight_decay": 0.0
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0,1",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "418.67",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34058272768
            },
            "1": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34058272768
            }
        }
    },
    "batch_size": 1024,
    "epoch_size": 364,
    "chunk_sizes": {},
    "eval_batch_sizes": {},
    "n_parameters": 20070400,
    "metrics": {
        "val": {
            "0": {
                "precision": 0.9456593373674436,
                "recall": 0.9313742845341358,
                "f1-score": 0.9384624531779535,
                "support": 33894
            },
            "1": {
                "precision": 0.9455068797836848,
                "recall": 0.9565831274267561,
                "f1-score": 0.9510127540109883,
                "support": 45328
            },
            "2": {
                "precision": 0.943363446838082,
                "recall": 0.9491347666491872,
                "f1-score": 0.9462403067003572,
                "support": 5721
            },
            "3": {
                "precision": 0.8758782201405152,
                "recall": 0.8519362186788155,
                "f1-score": 0.8637413394919169,
                "support": 439
            },
            "4": {
                "precision": 0.8476128188358404,
                "recall": 0.8531928900592495,
                "f1-score": 0.8503937007874015,
                "support": 1519
            },
            "5": {
                "precision": 0.9040202825063383,
                "recall": 0.8981648074847067,
                "f1-score": 0.9010830324909747,
                "support": 2779
            },
            "6": {
                "precision": 0.9470443349753694,
                "recall": 0.9372333942717855,
                "f1-score": 0.9421133231240428,
                "support": 3282
            },
            "accuracy": 0.9423205180611433,
            "macro avg": {
                "precision": 0.9155836172067533,
                "recall": 0.9110884984435196,
                "f1-score": 0.9132924156833766,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9423162366327669,
                "recall": 0.9423205180611433,
                "f1-score": 0.9422801730790529,
                "support": 92962
            },
            "roc_auc": 0.9944639690512809,
            "score": 0.9423205180611433
        },
        "test": {
            "0": {
                "precision": 0.9468564308989841,
                "recall": 0.932732250755287,
                "f1-score": 0.9397412727099781,
                "support": 42368
            },
            "1": {
                "precision": 0.9449290502306956,
                "recall": 0.9578369601666049,
                "f1-score": 0.9513392231103632,
                "support": 56661
            },
            "2": {
                "precision": 0.942876997915219,
                "recall": 0.948678506502587,
                "f1-score": 0.9457688554300849,
                "support": 7151
            },
            "3": {
                "precision": 0.8489208633093526,
                "recall": 0.8597449908925319,
                "f1-score": 0.8542986425339366,
                "support": 549
            },
            "4": {
                "precision": 0.8536853685368537,
                "recall": 0.8172722485518694,
                "f1-score": 0.8350820554210385,
                "support": 1899
            },
            "5": {
                "precision": 0.8997682502896871,
                "recall": 0.8943276706017852,
                "f1-score": 0.8970397111913356,
                "support": 3473
            },
            "6": {
                "precision": 0.9511343804537522,
                "recall": 0.9300341296928327,
                "f1-score": 0.9404659188955997,
                "support": 4102
            },
            "accuracy": 0.9424799703966334,
            "macro avg": {
                "precision": 0.912595905947792,
                "recall": 0.9058038224519284,
                "f1-score": 0.9091050970417623,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9424301095688324,
                "recall": 0.9424799703966334,
                "f1-score": 0.9424027257668574,
                "support": 116203
            },
            "roc_auc": 0.9942000293718711,
            "score": 0.9424799703966334
        }
    },
    "time": "03h 33m 33s"
}
