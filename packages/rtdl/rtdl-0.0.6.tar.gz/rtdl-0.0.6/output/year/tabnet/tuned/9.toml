seed = 9

[data]
normalization = 'quantile_normal'
path = 'data/year'
y_policy = 'mean_std'

[model]
batch_momentum = 0.95
feature_dim = 64
num_decision_steps = 3
relaxation_factor = 1.478400764417078
virtual_batch_size = 512

[training]
batch_size = 16384
display_steps = 100
epochs = 50000
grad_thresh = 2000.0
patience = 16
sparsity_loss_weight = 0.001114122016424037

    [training.schedule]
    decay_rate = 0.7659349159097861
    decay_steps = 100
    learning_rate = 0.003316750775989794
