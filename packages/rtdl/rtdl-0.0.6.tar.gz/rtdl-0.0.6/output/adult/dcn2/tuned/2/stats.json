{
    "dataset": "adult",
    "algorithm": "dcn2",
    "config": {
        "data": {
            "cat_policy": "indices",
            "normalization": "quantile_normal",
            "path": "data/adult"
        },
        "model": {
            "cross_dropout": 0.0762396988572804,
            "d": 197,
            "d_embedding": 163,
            "hidden_dropout": 0.367847757615804,
            "n_cross_layers": 2,
            "n_hidden_layers": 2,
            "stacked": false
        },
        "seed": 2,
        "training": {
            "batch_size": 256,
            "eval_batch_size": 8192,
            "lr": 0.0001504843145080851,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 0.000123327285667605
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "epoch_size": 102,
    "n_parameters": 431312,
    "best_epoch": 42,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.899506570912111,
                "recall": 0.9310745891276865,
                "f1-score": 0.9150183878342113,
                "support": 19775
            },
            "1": {
                "precision": 0.7556909840473203,
                "recall": 0.6720867208672087,
                "f1-score": 0.7114411069861627,
                "support": 6273
            },
            "accuracy": 0.8687039312039312,
            "macro avg": {
                "precision": 0.8275987774797156,
                "recall": 0.8015806549974476,
                "f1-score": 0.813229747410187,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8648722352086853,
                "recall": 0.8687039312039312,
                "f1-score": 0.8659919642024619,
                "support": 26048
            },
            "roc_auc": 0.9260591465883424,
            "score": 0.8687039312039312
        },
        "val": {
            "0": {
                "precision": 0.8885030864197531,
                "recall": 0.9314459049544995,
                "f1-score": 0.9094678645473394,
                "support": 4945
            },
            "1": {
                "precision": 0.744920993227991,
                "recall": 0.6313775510204082,
                "f1-score": 0.683465654124957,
                "support": 1568
            },
            "accuracy": 0.8592046675879011,
            "macro avg": {
                "precision": 0.8167120398238721,
                "recall": 0.7814117279874538,
                "f1-score": 0.7964667593361482,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8539358021997802,
                "recall": 0.8592046675879011,
                "f1-score": 0.8550579972139608,
                "support": 6513
            },
            "roc_auc": 0.9109872500567466,
            "score": 0.8592046675879011
        },
        "test": {
            "0": {
                "precision": 0.8872526461113668,
                "recall": 0.9302774427020507,
                "f1-score": 0.9082558002590978,
                "support": 12435
            },
            "1": {
                "precision": 0.7326549491211841,
                "recall": 0.6177847113884556,
                "f1-score": 0.6703343207786713,
                "support": 3846
            },
            "accuracy": 0.8564584484982495,
            "macro avg": {
                "precision": 0.8099537976162754,
                "recall": 0.7740310770452532,
                "f1-score": 0.7892950605188845,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8507326078689835,
                "recall": 0.8564584484982495,
                "f1-score": 0.8520524951745378,
                "support": 16281
            },
            "roc_auc": 0.9106125017015158,
            "score": 0.8564584484982495
        }
    },
    "time": "0:00:55"
}
