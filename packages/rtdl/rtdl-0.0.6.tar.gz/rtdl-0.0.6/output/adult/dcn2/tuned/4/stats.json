{
    "dataset": "adult",
    "algorithm": "dcn2",
    "config": {
        "data": {
            "cat_policy": "indices",
            "normalization": "quantile_normal",
            "path": "data/adult"
        },
        "model": {
            "cross_dropout": 0.0762396988572804,
            "d": 197,
            "d_embedding": 163,
            "hidden_dropout": 0.367847757615804,
            "n_cross_layers": 2,
            "n_hidden_layers": 2,
            "stacked": false
        },
        "seed": 4,
        "training": {
            "batch_size": 256,
            "eval_batch_size": 8192,
            "lr": 0.0001504843145080851,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 0.000123327285667605
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "epoch_size": 102,
    "n_parameters": 431312,
    "best_epoch": 56,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8967551622418879,
                "recall": 0.9377496839443742,
                "f1-score": 0.9167943837444998,
                "support": 19775
            },
            "1": {
                "precision": 0.7707208046191097,
                "recall": 0.6596524788777299,
                "f1-score": 0.7108744202027143,
                "support": 6273
            },
            "accuracy": 0.870777027027027,
            "macro avg": {
                "precision": 0.8337379834304988,
                "recall": 0.798701081411052,
                "f1-score": 0.813834401973607,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8664029845173913,
                "recall": 0.870777027027027,
                "f1-score": 0.8672037844164278,
                "support": 26048
            },
            "roc_auc": 0.9285612793214272,
            "score": 0.870777027027027
        },
        "val": {
            "0": {
                "precision": 0.8849252013808976,
                "recall": 0.9330637007077857,
                "f1-score": 0.9083571217639531,
                "support": 4945
            },
            "1": {
                "precision": 0.7451886066204773,
                "recall": 0.6173469387755102,
                "f1-score": 0.6752703174049529,
                "support": 1568
            },
            "accuracy": 0.8570551205281745,
            "macro avg": {
                "precision": 0.8150569040006874,
                "recall": 0.775205319741648,
                "f1-score": 0.791813719584453,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8512837181037074,
                "recall": 0.8570551205281745,
                "f1-score": 0.8522416436072031,
                "support": 6513
            },
            "roc_auc": 0.9098927488083202,
            "score": 0.8570551205281745
        },
        "test": {
            "0": {
                "precision": 0.8869671692048672,
                "recall": 0.9320466425412143,
                "f1-score": 0.9089483177789976,
                "support": 12435
            },
            "1": {
                "precision": 0.7370877411325452,
                "recall": 0.6159646385855434,
                "f1-score": 0.6711048158640227,
                "support": 3846
            },
            "accuracy": 0.857379767827529,
            "macro avg": {
                "precision": 0.8120274551687061,
                "recall": 0.7740056405633788,
                "f1-score": 0.7900265668215102,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8515617100582453,
                "recall": 0.857379767827529,
                "f1-score": 0.852763433044338,
                "support": 16281
            },
            "roc_auc": 0.9104247861108655,
            "score": 0.857379767827529
        }
    },
    "time": "0:01:00"
}
