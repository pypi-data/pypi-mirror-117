seed = 12

[data]
normalization = 'quantile_normal'
path = 'data/yahoo'
y_policy = 'mean_std'

[model]
batch_momentum = 0.95
feature_dim = 32
num_decision_steps = 8
relaxation_factor = 1.035784319515756
virtual_batch_size = 512

[training]
batch_size = 16384
display_steps = 100
epochs = 50000
grad_thresh = 2000.0
patience = 16
sparsity_loss_weight = 1.354644301319665e-05

    [training.schedule]
    decay_rate = 0.7449109507075434
    decay_steps = 2000
    learning_rate = 0.003411657594699632
