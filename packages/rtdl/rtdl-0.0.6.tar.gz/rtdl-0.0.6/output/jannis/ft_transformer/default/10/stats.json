{"dataset": "jannis", "algorithm": "ft_transformer", "config": {"data": {"normalization": "quantile_normal", "path": "data/jannis"}, "model": {"activation": "reglu", "attention_dropout": 0.2, "d_ffn_factor": 1.333333333333333, "d_token": 192, "ffn_dropout": 0.1, "initialization": "kaiming", "n_heads": 8, "n_layers": 3, "prenormalization": true, "residual_dropout": 0.0}, "seed": 10, "training": {"batch_size": 512, "eval_batch_size": 8192, "lr": 0.0001, "lr_n_decays": 0, "n_epochs": 1000000000, "optimizer": "adamw", "patience": 16, "weight_decay": 1e-05}}, "environment": {"devices": {"CUDA_VISIBLE_DEVICES": "0", "torch.version.cuda": "10.1", "torch.backends.cudnn.version()": 7603, "torch.cuda.nccl.version()": 2708, "driver": "450.80.02", "0": {"name": "Tesla V100-PCIE-32GB", "total_memory": 34089730048}}}, "epoch_size": 105, "n_parameters": 911422, "best_epoch": 25, "metrics": {"train": {"0": {"precision": 0.6282722513089005, "recall": 0.2222222222222222, "f1-score": 0.3283173734610123, "support": 1080}, "1": {"precision": 0.6971327074346613, "recall": 0.7455630936227952, "f1-score": 0.720535011801731, "support": 18425}, "2": {"precision": 0.7697610294117647, "recall": 0.7104984093319194, "f1-score": 0.7389434211977501, "support": 9430}, "3": {"precision": 0.8390531112634593, "recall": 0.8439540826674239, "f1-score": 0.8414964610717897, "support": 24653}, "accuracy": 0.7741098753452266, "macro avg": {"precision": 0.7335547748546963, "recall": 0.6305594519610902, "f1-score": 0.6573230668830707, "support": 53588}, "weighted avg": {"precision": 0.7738155375313176, "recall": 0.7741098753452266, "f1-score": 0.7715176732194222, "support": 53588}, "score": 0.7741098753452266}, "val": {"0": {"precision": 0.391304347826087, "recall": 0.13333333333333333, "f1-score": 0.19889502762430938, "support": 270}, "1": {"precision": 0.6428864288642886, "recall": 0.6807032776210115, "f1-score": 0.6612546125461253, "support": 4607}, "2": {"precision": 0.7144156434743065, "recall": 0.666525243954179, "f1-score": 0.689640035118525, "support": 2357}, "3": {"precision": 0.8097607962754856, "recall": 0.81829980532122, "f1-score": 0.8140079076898249, "support": 6164}, "accuracy": 0.7304821615166442, "macro avg": {"precision": 0.6395918041100419, "recall": 0.574715415057436, "f1-score": 0.5909493957446962, "support": 13398}, "weighted avg": {"precision": 0.7271736954472201, "recall": 0.7304821615166442, "f1-score": 0.7272076401875659, "support": 13398}, "score": 0.7304821615166442}, "test": {"0": {"precision": 0.4095238095238095, "recall": 0.12759643916913946, "f1-score": 0.19457013574660634, "support": 337}, "1": {"precision": 0.6345029239766082, "recall": 0.6783605418548107, "f1-score": 0.6556991774383079, "support": 5758}, "2": {"precision": 0.71449758991472, "recall": 0.6538853070919579, "f1-score": 0.6828490432317506, "support": 2947}, "3": {"precision": 0.8030555912183849, "recall": 0.8118105126541207, "f1-score": 0.8074093197366723, "support": 7705}, "accuracy": 0.7243685436197528, "macro avg": {"precision": 0.6403949786583807, "recall": 0.5679132001925072, "f1-score": 0.5851319190383342, "support": 16747}, "weighted avg": {"precision": 0.7216005904271314, "recall": 0.7243685436197528, "f1-score": 0.7209966524399243, "support": 16747}, "score": 0.7243685436197528}}, "time": "0:03:47"}
