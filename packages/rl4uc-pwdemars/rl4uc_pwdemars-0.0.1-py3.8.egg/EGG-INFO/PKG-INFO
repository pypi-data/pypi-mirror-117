Metadata-Version: 2.1
Name: rl4uc-pwdemars
Version: 0.0.1
Summary: Reinforcement learning environment for the unit commitment problem
Home-page: UNKNOWN
Author: Patrick de Mars
Author-email: pwdemars@gmail.com
License: UNKNOWN
Description: # RL4UC: Reinforcement Learning for Unit Commitment
        
        This project contains an RL environment for the unit commitment problem.
        
        ## Installation
        
        You can install this repository by running: 
        
        ```
        git clone https://github.com/pwdemars/rl4uc.git
        cd rl4uc
        pip install .
        ```
        
        ## Example usage:
        
        Below we will try an action on the 5 generator system. An action is a commitment decision for the following time period, defined by a binary numpy array: 1 indicates that we want to turn (or leave) the generator on, 0 indicates turn or leave it off. 
        
        ```python 
        from rl4uc.environment import make_env
        import numpy as np
        
        # Create an environment, 5 generators by default.
        env = make_env()
        
        # Reset the environment to a random demand profile.
        obs_init = env.reset()
        
        # Define a commitment decision for the next time period.
        action = np.array([1,1,0,0,0]) # Turn on generators 0 & 1, turns all others off.
        
        # Take the action, observe the reward.
        observation, reward, done = env.step(action)
        
        print("Dispatch: {}".format(env.disp))
        print("Finished? {}".format(done))
        print("Reward: {:.2f}".format(reward))
        ```
        
        
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
