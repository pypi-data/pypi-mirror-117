# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/12_modeling-seq2seq-translation.ipynb (unless otherwise specified).

__all__ = ['BlearnerForTranslation']

# Cell
import torch
from datasets import list_datasets, load_dataset
from transformers import *
from fastai.text.all import *

from ...utils import *
from ...data.core import get_blurr_tfm
from ...data.seq2seq.core import *
from ...data.seq2seq.translation import *
from ..core import *
from .core import *

logging.set_verbosity_error()

# Cell
@delegates(Blearner.__init__)
class BlearnerForTranslation(Blearner):

    def __init__(self, dls, hf_model, **kwargs):
        super().__init__(dls, hf_model, **kwargs)

    @classmethod
    def get_model_cls(cls):
        return AutoModelForSeq2SeqLM

    @classmethod
    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name):
        return f'translate {src_lang_name} to {trg_lang_name}: {inp}'

    @classmethod
    def get_metrics_cb(self):
        seq2seq_metrics = {
            'bleu': { 'returns': "bleu" },
            'meteor': { 'returns': "meteor" },
            'sacrebleu': { 'returns': "score" }
        }

        return HF_Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)

    @classmethod
    def _create_learner(cls, data,
                        pretrained_model_name_or_path,
                        preprocess_func,
                        src_lang_name, src_lang_attr,
                        trg_lang_name, trg_lang_attr,
                        max_length, max_target_length,
                        dblock_splitter,
                        hf_tok_kwargs, text_gen_kwargs, dl_kwargs, learner_kwargs):

        # we need to find the architecture to ensure "mbart" specific tokenizer kwargs are included
        model_cls = cls.get_model_cls()
        model = model_cls.from_pretrained(pretrained_model_name_or_path)
        hf_arch = BLURR.get_model_architecture(type(model).__name__)

        if (hf_arch == 'mbart'):
            hf_tok_kwargs = { **{'src_lang': 'en_XX', 'tgt_lang': 'en_XX'}, **hf_tok_kwargs }

        # get our hf objects
        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path,
                                                                          model_cls=model_cls,
                                                                          tokenizer_kwargs=hf_tok_kwargs)

        # if we need to preprocess the raw data before creating our DataLoaders
        if (preprocess_func):
            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text_attr, summary_attr)

        # update text generation kwargs
        text_gen_kwargs = { **text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task='translation') }

        # not all "summarization" parameters are for the model.generate method ... remove them here
        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())
        for k in text_gen_kwargs.copy():
            if k not in generate_func_args: del text_gen_kwargs[k]

        # update our text generation kwargs for mbart
        if (hf_arch == 'mbart'):
            text_gen_kwargs = { **{'decoder_start_token_id': 'en_XX'}, **text_gen_kwargs }

        # build dblock, dls, and default metrics (optional)
        if (isinstance(data, pd.DataFrame)):
            get_x = Pipeline(funcs=[ColReader(src_lang_attr)])
            get_y = ColReader(trg_lang_attr)
        else:
            get_x = Pipeline(funcs=[ItemGetter(src_lang_attr)])
            get_y = ItemGetter(trg_lang_attr)

        if (hf_arch == 't5'):
            get_x.add(partial(cls._add_t5_prefix, src_lang_name=src_lang_name, trg_lang_name=trg_lang_name))

        before_batch_tfm = HF_Seq2SeqBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,
                                                          max_length=max_length,
                                                          max_target_length=max_target_length,
                                                          text_gen_kwargs=text_gen_kwargs)

        blocks = (HF_Seq2SeqBlock(before_batch_tfm=before_batch_tfm), noop)
        dblock = DataBlock(blocks=blocks,
                           get_x=get_x,
                           get_y=get_y,
                           splitter=dblock_splitter)

        dls = dblock.dataloaders(data, **dl_kwargs.copy())

        # return BLearner instance
        learner_kwargs['splitter'] = learner_kwargs.pop('splitter', partial(seq2seq_splitter, arch=hf_arch))
        learner_kwargs['loss_func'] = learner_kwargs.pop('loss_func', CrossEntropyLossFlat())
        return cls(dls, hf_model, **learner_kwargs.copy())

    @classmethod
    def from_dataframe(cls, df,
                       pretrained_model_name_or_path,
                       preprocess_func=None,
                       src_lang_name='English', src_lang_attr='src_lang',
                       trg_lang_name='English', trg_lang_attr='trg_lang',
                       max_length=None, max_target_length=None,
                       dblock_splitter=ColSplitter(),
                       hf_tok_kwargs={}, text_gen_kwargs={}, dl_kwargs={}, learner_kwargs={}):

        return cls._create_learner(df,
                                   pretrained_model_name_or_path=pretrained_model_name_or_path,
                                   preprocess_func=preprocess_func,
                                   src_lang_name=src_lang_name,
                                   src_lang_attr=src_lang_attr,
                                   trg_lang_name=trg_lang_name,
                                   trg_lang_attr=trg_lang_attr,
                                   max_length=max_length,
                                   max_target_length=max_target_length,
                                   dblock_splitter=dblock_splitter,
                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs,
                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)


    @classmethod
    def from_csv(cls, csv_file,
                 pretrained_model_name_or_path,
                 preprocess_func=None,
                 src_lang_name='English', src_lang_attr='src_lang',
                 trg_lang_name='English', trg_lang_attr='trg_lang',
                 max_length=None, max_target_length=None,
                 dblock_splitter=ColSplitter(),
                 hf_tok_kwargs={}, text_gen_kwargs={}, dl_kwargs={}, learner_kwargs={}):

        df = pd.read_csv(csv_file)

        return cls.from_dataframe(df,
                                  pretrained_model_name_or_path=pretrained_model_name_or_path,
                                  preprocess_func=preprocess_func,
                                  src_lang_name=src_lang_name,
                                  src_lang_attr=src_lang_attr,
                                  trg_lang_name=trg_lang_name,
                                  trg_lang_attr=trg_lang_attr,
                                  max_length=max_length,
                                  max_target_length=max_target_length,
                                  dblock_splitter=dblock_splitter,
                                  hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs,
                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)

    @classmethod
    def from_dictionaries(cls, ds,
                          pretrained_model_name_or_path,
                          preprocess_func=None,
                          src_lang_name='English', src_lang_attr='src_lang',
                          trg_lang_name='English', trg_lang_attr='trg_lang',
                          max_length=None, max_target_length=None,
                          dblock_splitter=RandomSplitter(),
                          hf_tok_kwargs={}, text_gen_kwargs={}, dl_kwargs={}, learner_kwargs={}):

        return cls._create_learner(ds,
                                   pretrained_model_name_or_path=pretrained_model_name_or_path,
                                   preprocess_func=preprocess_func,
                                   src_lang_name=src_lang_name,
                                   src_lang_attr=src_lang_attr,
                                   trg_lang_name=trg_lang_name,
                                   trg_lang_attr=trg_lang_attr,
                                   max_length=max_length,
                                   max_target_length=max_target_length,
                                   dblock_splitter=dblock_splitter,
                                   hf_tok_kwargs=hf_tok_kwargs, text_gen_kwargs=text_gen_kwargs,
                                   dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)
