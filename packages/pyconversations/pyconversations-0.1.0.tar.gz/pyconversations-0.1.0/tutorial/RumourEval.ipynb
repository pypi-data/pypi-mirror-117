{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rotary-contact",
   "metadata": {},
   "source": [
    "# RumourEval-2019 - A Heterogeneous Example \n",
    "\n",
    "This notebooks gives a brief example of how to use pyconversations, particularly for a collection of multi-platform data. This dataset was specifically selected due to its multi-platform nature, its public availability, and the fact that it was distributed (by-and-large) as a raw data dump (with some minor structural annotations, thougn unneceessary when using pyconversations).\n",
    "\n",
    "Specifically, this tutorial uses the data from [SemEval-2019 Task 7: RumourEval](https://aclanthology.org/S19-2147/), which you will need a copy of if you wish to follow this tutorial exactly.\n",
    "Information on how to obtain a copy of this data is available at the [CodaLab Competition page](https://competitions.codalab.org/competitions/19938).\n",
    "\n",
    "Though this dataset can be read out of the box without pyconversations, this package contains several aspects out of the box (redaction, segmentation, feature generation) that make it a valuable package when dealing with data like this.\n",
    "For example, one could develop a reader that splits up conversations per their file organization or, using pyconversations, one could write a much simpler file reader and allow pyconversations to handle the \"heavy-lifting\" of segmentation.\n",
    "\n",
    "To gain a bit clearer of a view of what this dataset's construction was all about, here's the abstract from the task's paper:\n",
    "\n",
    "```\n",
    "Since the first RumourEval shared task in 2017, interest in automated claim validation has greatly increased, as the danger of “fake news” has become a mainstream concern. However automated support for rumour verification remains in its infancy. It is therefore important that a shared task in this area continues to provide a focus for effort, which is likely to increase. Rumour verification is characterised by the need to consider evolving conversations and news updates to reach a verdict on a rumour’s veracity. As in RumourEval 2017 we provided a dataset of dubious posts and ensuing conversations in social media, annotated both for stance and veracity. The social media rumours stem from a variety of breaking news stories and the dataset is expanded to include Reddit as well as new Twitter posts. There were two concrete tasks; rumour stance prediction and rumour verification, which we present in detail along with results achieved by participants. We received 22 system submissions (a 70% increase from RumourEval 2017) many of which used state-of-the-art methodology to tackle the challenges involved.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "paperback-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "typical-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['subtaskaenglish', 'subtaskbenglish']),\n",
       " dict_keys(['subtaskaenglish', 'subtaskbenglish']),\n",
       " dict_keys(['subtaskaenglish', 'subtaskbenglish', 'subtaskbdanish', 'subtaskbrussian']))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update this to your local data directory\n",
    "DATA_PATH = '/Users/hsh28/data/rumoureval2019/'  \n",
    "TRAIN_PATH = DATA_PATH + 'rumoureval-2019-training-data/'\n",
    "TEST_PATH = DATA_PATH + 'rumoureval-2019-test-data/'\n",
    "\n",
    "# Answer keys, we can use these to extract some annotations\n",
    "# and tag data with their associated split too\n",
    "TRAIN_KEY = json.load(open(TRAIN_PATH + 'train-key.json'))\n",
    "DEV_KEY = json.load(open(TRAIN_PATH + 'dev-key.json'))\n",
    "FINAL = json.load(open(DATA_PATH + 'final-eval-key.json'))\n",
    "\n",
    "TRAIN_KEY.keys(), DEV_KEY.keys(), FINAL.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complicated-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyconversations.convo import Conversation\n",
    "from pyconversations.message import RedditPost\n",
    "from pyconversations.message import Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-practitioner",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "Now that we've loaded the annotations and pyconversations, let's dive into reading the file and verifying the appropriate post counts / annotation splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-yesterday",
   "metadata": {},
   "source": [
    "Here, let's write two small helper functions to bulk read a file and extract either all tweets or all Reddit posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italian-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tweets(path):\n",
    "    return Tweet.parse_raw(json.load(open(path)), lang_detect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aboriginal-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reddit_posts(path):\n",
    "    raw = json.load(open(path))\n",
    "    if type(raw) == dict:\n",
    "        return RedditPost.parse_raw(raw, lang_detect=True)\n",
    "    else:\n",
    "        return [y for x in raw for y in RedditPost.parse_raw(x, lang_detect=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-peter",
   "metadata": {},
   "source": [
    "All pyconversations messages should be stored in a `Conversation` object for maximal functionality. \n",
    "Here, we'll exhibit this bulk reading by making minimal assumptions about the data (other than its raw data from either Twitter or Reddit) and, provided we appropriately tag posts, we can easily recover (and verify) the data has been properly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polished-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = Conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automated-warehouse",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading train+dev: 100%|██████████| 5568/5568 [00:13<00:00, 415.21it/s]\n",
      "reading test: 100%|██████████| 1066/1066 [00:02<00:00, 501.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# reading Twitter data \n",
    "for tweet_path in tqdm([x for pat in ('source-tweet', 'replies') for x in glob(TRAIN_PATH + f'twitter-english/*/*/{pat}/*.json')], desc='reading train+dev'):\n",
    "    for t in read_tweets(tweet_path):\n",
    "        subject = tweet_path.split('/')[-3]\n",
    "        tstr = str(t.uid)\n",
    "        if tstr in TRAIN_KEY['subtaskaenglish']:\n",
    "            t.add_tag('split=TRAIN')\n",
    "            t.add_tag(f'taskA={TRAIN_KEY[\"subtaskaenglish\"][tstr]}')\n",
    "            if tstr in TRAIN_KEY['subtaskbenglish']:\n",
    "                t.add_tag(f'taskB={TRAIN_KEY[\"subtaskbenglish\"][tstr]}')\n",
    "        elif tstr in DEV_KEY['subtaskaenglish']:\n",
    "            t.add_tag('split=DEV')\n",
    "            t.add_tag(f'taskA={DEV_KEY[\"subtaskaenglish\"][tstr]}')\n",
    "            if tstr in DEV_KEY['subtaskbenglish']:\n",
    "                t.add_tag(f'taskB={DEV_KEY[\"subtaskbenglish\"][tstr]}')\n",
    "        elif tstr in FINAL['subtaskaenglish']:\n",
    "            t.add_tag('split=TEST')\n",
    "            t.add_tag(f'taskA={FINAL[\"subtaskaenglish\"][tstr]}')\n",
    "            if tstr in FINAL['subtaskbenglish']:\n",
    "                t.add_tag(f'taskB={FINAL[\"subtaskbenglish\"][tstr]}')\n",
    "            \n",
    "        t.add_tag(subject)\n",
    "\n",
    "        data_set.add_post(t)\n",
    "        \n",
    "for tweet_path in tqdm([x for pat in ('source-tweet', 'replies') for x in glob(TEST_PATH + f'twitter-en-test-data/*/*/{pat}/*.json')], desc='reading test'):\n",
    "    for t in read_tweets(tweet_path):\n",
    "        subject = tweet_path.split('/')[-3]\n",
    "        tstr = str(t.uid)\n",
    "        if tstr in FINAL['subtaskaenglish']:\n",
    "            t.add_tag('split=TEST')\n",
    "            t.add_tag(f'taskA={FINAL[\"subtaskaenglish\"][tstr]}')\n",
    "            if tstr in FINAL['subtaskbenglish']:\n",
    "                t.add_tag(f'taskB={FINAL[\"subtaskbenglish\"][tstr]}')\n",
    "            \n",
    "        t.add_tag(subject)\n",
    "        \n",
    "        data_set.add_post(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "selective-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading train: 100%|██████████| 728/728 [00:05<00:00, 130.30it/s]\n",
      "reading dev: 100%|██████████| 446/446 [00:03<00:00, 116.94it/s]\n",
      "reading test: 100%|██████████| 761/761 [00:04<00:00, 173.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# reading Reddit data \n",
    "for reddit_path in tqdm(\n",
    "    list(glob(TRAIN_PATH + 'reddit-training-data/*/raw.json')) + \n",
    "    [x for pat in ('source-tweet', 'replies') for x in glob(TRAIN_PATH + f'reddit-training-data/*/{pat}/*.json')],\n",
    "    desc='reading train'\n",
    "):\n",
    "    for t in read_reddit_posts(reddit_path):\n",
    "        t.add_tag('split=TRAIN')\n",
    "        if t.uid in TRAIN_KEY['subtaskaenglish']:\n",
    "            t.add_tag(f'taskA={TRAIN_KEY[\"subtaskaenglish\"][t.uid]}')\n",
    "        \n",
    "        if t.uid in TRAIN_KEY['subtaskbenglish']:\n",
    "            t.add_tag(f'taskB={TRAIN_KEY[\"subtaskbenglish\"][t.uid]}')\n",
    "        \n",
    "        data_set.add_post(t)\n",
    "        \n",
    "for reddit_path in tqdm(\n",
    "    list(glob(TRAIN_PATH + 'reddit-dev-data/*/raw.json')) + \n",
    "    [x for pat in ('source-tweet', 'replies') for x in glob(TRAIN_PATH + f'reddit-dev-data/*/{pat}/*.json')],\n",
    "    desc='reading dev'\n",
    "):\n",
    "    for t in read_reddit_posts(reddit_path):\n",
    "        t.add_tag('split=DEV')\n",
    "\n",
    "        if t.uid in DEV_KEY['subtaskaenglish']:\n",
    "            t.add_tag(f'taskA={DEV_KEY[\"subtaskaenglish\"][t.uid]}')\n",
    "        \n",
    "        if t.uid in DEV_KEY['subtaskbenglish']:\n",
    "            t.add_tag(f'taskB={DEV_KEY[\"subtaskbenglish\"][t.uid]}')\n",
    "            \n",
    "        data_set.add_post(t)\n",
    "        \n",
    "for reddit_path in tqdm(\n",
    "    list(glob(TRAIN_PATH + 'reddit-test-data/*/raw.json')) + \n",
    "    [x for pat in ('source-tweet', 'replies') for x in glob(TEST_PATH + f'reddit-test-data/*/{pat}/*.json')],\n",
    "    'reading test'\n",
    "):\n",
    "    for t in read_reddit_posts(reddit_path):\n",
    "        t.add_tag('split=TEST')\n",
    "        \n",
    "        if t.uid in FINAL['subtaskaenglish']:\n",
    "            t.add_tag(f'taskA={FINAL[\"subtaskaenglish\"][t.uid]}')\n",
    "        \n",
    "        if t.uid in FINAL['subtaskbenglish']:\n",
    "            t.add_tag(f'taskB={FINAL[\"subtaskbenglish\"][t.uid]}')\n",
    "        \n",
    "        data_set.add_post(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-inclusion",
   "metadata": {},
   "source": [
    "## Verifying Correctness\n",
    "\n",
    "In the [original paper](https://aclanthology.org/S19-2147.pdf), Tables 3 and 4 show us the anticipated data in this dataset. \n",
    "Here, we just have some print outs that verify correctness of these counts. \n",
    "Notice in this portion:\n",
    "\n",
    "* how we operate the filter operation (on a `Conversation`) to consider subsets of the original\n",
    "* how we use the segment operation to split out disjoint threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "major-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Train (including DEV)\n",
      "\tSubtask A\n",
      "\t\tTotal messages: 5568 (5568 in paper)\n",
      "\t\tSupport messages: 1004 (1004 in paper)\n",
      "\t\tDeny messages: 415 (415 in paper)\n",
      "\t\tQuery messages: 464 (464 in paper)\n",
      "\t\tComment messages: 3685 (3685 in paper)\n",
      "\tSubtask B\n",
      "\t\tTotal threads: 327 (325 in paper)\n",
      "\t\tTrue threads: 145 (145 in paper)\n",
      "\t\tFalse threads: 74 (74 in paper)\n",
      "\t\tUnverified threads: 106 (106 in paper)\n",
      "Twitter Test\n",
      "\tSubtask A\n",
      "\t\tTotal messages: 1066 (1066 in paper)\n",
      "\t\tSupport messages: 141 (141 in paper)\n",
      "\t\tDeny messages: 92 (92 in paper)\n",
      "\t\tQuery messages: 62 (62 in paper)\n",
      "\t\tComment messages: 771 (771 in paper)\n",
      "\tSubtask B\n",
      "\t\tTotal threads: 61 (56 in paper)\n",
      "\t\tTrue threads: 22 (22 in paper)\n",
      "\t\tFalse threads: 30 (30 in paper)\n",
      "\t\tUnverified threads: 4 (4 in paper)\n"
     ]
    }
   ],
   "source": [
    "print('Twitter Train (including DEV)')\n",
    "\n",
    "train = data_set.filter(by_platform={'Twitter'}, by_tags={'split=TRAIN'}) + data_set.filter(by_platform={'Twitter'}, by_tags={'split=DEV'})\n",
    "\n",
    "print('\\tSubtask A')\n",
    "print(f'\\t\\tTotal messages: {len(train.posts)} (5568 in paper)')\n",
    "\n",
    "train_supp = train.filter(by_tags={'taskA=support'})\n",
    "print(f'\\t\\tSupport messages: {len(train_supp.posts)} (1004 in paper)')\n",
    "\n",
    "train_deny = train.filter(by_tags={'taskA=deny'})\n",
    "print(f'\\t\\tDeny messages: {len(train_deny.posts)} (415 in paper)')\n",
    "\n",
    "train_quest = train.filter(by_tags={'taskA=query'})\n",
    "print(f'\\t\\tQuery messages: {len(train_quest.posts)} (464 in paper)')\n",
    "\n",
    "train_comm = train.filter(by_tags={'taskA=comment'})\n",
    "print(f'\\t\\tComment messages: {len(train_comm.posts)} (3685 in paper)')\n",
    "\n",
    "print('\\tSubtask B')\n",
    "print(f'\\t\\tTotal threads: {len(train.segment())} (325 in paper)')\n",
    "\n",
    "train_true = train.filter(by_tags={'taskB=true'})\n",
    "print(f'\\t\\tTrue threads: {len(train_true.posts)} (145 in paper)')\n",
    "\n",
    "train_false = train.filter(by_tags={'taskB=false'})\n",
    "print(f'\\t\\tFalse threads: {len(train_false.posts)} (74 in paper)')\n",
    "\n",
    "train_unv = train.filter(by_tags={'taskB=unverified'})\n",
    "print(f'\\t\\tUnverified threads: {len(train_unv.posts)} (106 in paper)')\n",
    "\n",
    "print('Twitter Test')\n",
    "\n",
    "test = data_set.filter(by_platform={'Twitter'}, by_tags={'split=TEST'})\n",
    "\n",
    "print('\\tSubtask A')\n",
    "print(f'\\t\\tTotal messages: {len(test.posts)} (1066 in paper)')\n",
    "\n",
    "test_supp = test.filter(by_tags={'taskA=support'})\n",
    "print(f'\\t\\tSupport messages: {len(test_supp.posts)} (141 in paper)')\n",
    "\n",
    "test_deny = test.filter(by_tags={'taskA=deny'})\n",
    "print(f'\\t\\tDeny messages: {len(test_deny.posts)} (92 in paper)')\n",
    "\n",
    "test_quest = test.filter(by_tags={'taskA=query'})\n",
    "print(f'\\t\\tQuery messages: {len(test_quest.posts)} (62 in paper)')\n",
    "\n",
    "test_comm = test.filter(by_tags={'taskA=comment'})\n",
    "print(f'\\t\\tComment messages: {len(test_comm.posts)} (771 in paper)')\n",
    "\n",
    "print('\\tSubtask B')\n",
    "print(f'\\t\\tTotal threads: {len(test.segment())} (56 in paper)')\n",
    "\n",
    "test_true = test.filter(by_tags={'taskB=true'})\n",
    "print(f'\\t\\tTrue threads: {len(test_true.posts)} (22 in paper)')\n",
    "\n",
    "test_false = test.filter(by_tags={'taskB=false'})\n",
    "print(f'\\t\\tFalse threads: {len(test_false.posts)} (30 in paper)')\n",
    "\n",
    "test_unv = test.filter(by_tags={'taskB=unverified'})\n",
    "print(f'\\t\\tUnverified threads: {len(test_unv.posts)} (4 in paper)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "double-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Train (including DEV)\n",
      "\tSubtask A\n",
      "\t\tTotal messages: 1134 (1134 in paper)\n",
      "\t\tSupport messages: 23 (23 in paper)\n",
      "\t\tDeny messages: 45 (45 in paper)\n",
      "\t\tQuery messages: 51 (51 in paper)\n",
      "\t\tComment messages: 1015 (1015 in paper)\n",
      "\tSubtask B\n",
      "\t\tTotal threads: 40 (40 in paper)\n",
      "\t\tTrue threads: 9 (9 in paper)\n",
      "\t\tFalse threads: 24 (24 in paper)\n",
      "\t\tUnverified threads: 7 (7 in paper)\n",
      "Reddit Test\n",
      "\tSubtask A\n",
      "\t\tTotal messages: 761 (806 in paper)\n",
      "\t\tSupport messages: 16 (16 in paper)\n",
      "\t\tDeny messages: 9 (54 in paper)\n",
      "\t\tQuery messages: 31 (31 in paper)\n",
      "\t\tComment messages: 705 (705 in paper)\n",
      "\tSubtask B\n",
      "\t\tTotal threads: 25 (25 in paper)\n",
      "\t\tTrue threads: 9 (9 in paper)\n",
      "\t\tFalse threads: 10 (10 in paper)\n",
      "\t\tUnverified threads: 6 (6 in paper)\n"
     ]
    }
   ],
   "source": [
    "print('Reddit Train (including DEV)')\n",
    "\n",
    "train = data_set.filter(by_platform={'Reddit'}, by_tags={'split=TRAIN'}) + data_set.filter(by_platform={'Reddit'}, by_tags={'split=DEV'})\n",
    "\n",
    "print('\\tSubtask A')\n",
    "print(f'\\t\\tTotal messages: {len(train.posts)} (1134 in paper)')\n",
    "\n",
    "train_supp = train.filter(by_tags={'taskA=support'})\n",
    "print(f'\\t\\tSupport messages: {len(train_supp.posts)} (23 in paper)')\n",
    "\n",
    "train_deny = train.filter(by_tags={'taskA=deny'})\n",
    "print(f'\\t\\tDeny messages: {len(train_deny.posts)} (45 in paper)')\n",
    "\n",
    "train_quest = train.filter(by_tags={'taskA=query'})\n",
    "print(f'\\t\\tQuery messages: {len(train_quest.posts)} (51 in paper)')\n",
    "\n",
    "train_comm = train.filter(by_tags={'taskA=comment'})\n",
    "print(f'\\t\\tComment messages: {len(train_comm.posts)} (1015 in paper)')\n",
    "\n",
    "print('\\tSubtask B')\n",
    "print(f'\\t\\tTotal threads: {len(train.segment())} (40 in paper)')\n",
    "\n",
    "train_true = train.filter(by_tags={'taskB=true'})\n",
    "print(f'\\t\\tTrue threads: {len(train_true.posts)} (9 in paper)')\n",
    "\n",
    "train_false = train.filter(by_tags={'taskB=false'})\n",
    "print(f'\\t\\tFalse threads: {len(train_false.posts)} (24 in paper)')\n",
    "\n",
    "train_unv = train.filter(by_tags={'taskB=unverified'})\n",
    "print(f'\\t\\tUnverified threads: {len(train_unv.posts)} (7 in paper)')\n",
    "\n",
    "print('Reddit Test')\n",
    "\n",
    "test = data_set.filter(by_platform={'Reddit'}, by_tags={'split=TEST'})\n",
    "\n",
    "print('\\tSubtask A')\n",
    "print(f'\\t\\tTotal messages: {len(test.posts)} (806 in paper)')\n",
    "\n",
    "test_supp = test.filter(by_tags={'taskA=support'})\n",
    "print(f'\\t\\tSupport messages: {len(test_supp.posts)} (16 in paper)')\n",
    "\n",
    "test_deny = test.filter(by_tags={'taskA=deny'})\n",
    "print(f'\\t\\tDeny messages: {len(test_deny.posts)} (54 in paper)')\n",
    "\n",
    "test_quest = test.filter(by_tags={'taskA=query'})\n",
    "print(f'\\t\\tQuery messages: {len(test_quest.posts)} (31 in paper)')\n",
    "\n",
    "test_comm = test.filter(by_tags={'taskA=comment'})\n",
    "print(f'\\t\\tComment messages: {len(test_comm.posts)} (705 in paper)')\n",
    "\n",
    "print('\\tSubtask B')\n",
    "print(f'\\t\\tTotal threads: {len(test.segment())} (25 in paper)')\n",
    "\n",
    "test_true = test.filter(by_tags={'taskB=true'})\n",
    "print(f'\\t\\tTrue threads: {len(test_true.posts)} (9 in paper)')\n",
    "\n",
    "test_false = test.filter(by_tags={'taskB=false'})\n",
    "print(f'\\t\\tFalse threads: {len(test_false.posts)} (10 in paper)')\n",
    "\n",
    "test_unv = test.filter(by_tags={'taskB=unverified'})\n",
    "print(f'\\t\\tUnverified threads: {len(test_unv.posts)} (6 in paper)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-generation",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "Not bad! It appears that we've just about loaded everything per what is described in the paper minus:\n",
    "* A chunk of Reddit `deny` comments (45 total) from the test set\n",
    "* Some linkages in the Twitter data appear to be fragmented leading to increased thread counts... (I believe this may be the ill-formed thread referenced on line 114 [here](https://github.com/kochkinaelena/RumourEval2019/blob/master/preprocessing/preprocessing_tweets.py))\n",
    "\n",
    "We can also briefly enumerate through our keys and see if there is anything missing when inspecting the data through this lens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fallen-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_missing_ids(key, label):\n",
    "    print(label)\n",
    "    for task, annots in key.items():\n",
    "        for pid in annots:\n",
    "            if (pid.isnumeric() and int(pid) not in data_set.posts) or (not pid.isnumeric() and pid not in data_set.posts):\n",
    "                print('\\t', pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "novel-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "dev\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "output_missing_ids(TRAIN_KEY, 'train')\n",
    "output_missing_ids(DEV_KEY, 'dev')\n",
    "output_missing_ids(FINAL, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-contractor",
   "metadata": {},
   "source": [
    "Interestingly enough, it doesn't seem as though we have any missing messages (per these supplied annotation keys)! \n",
    "I also haven't found any additional data included with this data release. \n",
    "\n",
    "Hopefully this speeds up your handling of heterogenous platform data! If you notice anything off about this tutorial, submit a bug [here](https://github.com/hunter-heidenreich/pyconversations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-casino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
