{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f99b8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10464472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility functions used to download, open and display\n",
    " the contents of Wikimedia SQL dump files.\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Iterator, Optional, TextIO, Union\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import wget  # type: ignore\n",
    "\n",
    "# Custom type\n",
    "PathObject = Union[str, Path]\n",
    "\n",
    "\n",
    "# TODO: eventually will want to update the function calls to match rest of library -- e.g., file_path: string, mode: string, etc.\n",
    "# Done!\n",
    "@contextmanager\n",
    "def _open_file(\n",
    "    file_path: PathObject, encoding: Optional[str] = None\n",
    ") -> Iterator[TextIO]:\n",
    "    \"\"\"Custom context manager for opening both .gz and uncompressed files.\n",
    "\n",
    "    :param file_path: The path to the file\n",
    "    :type file_path: PathObject\n",
    "    :param encoding: Text encoding, defaults to None\n",
    "    :type encoding: Optional[str], optional\n",
    "    :yield: A file handle\n",
    "    :rtype: Iterator[TextIO]\n",
    "    \"\"\"\n",
    "\n",
    "    if str(file_path).endswith(\".gz\"):\n",
    "        infile = gzip.open(file_path, mode=\"rt\", encoding=encoding)\n",
    "    else:\n",
    "        infile = open(file_path, mode=\"r\", encoding=encoding)\n",
    "    try:\n",
    "        yield infile\n",
    "    finally:\n",
    "        infile.close()\n",
    "\n",
    "\n",
    "def head(file_path: PathObject, n_lines: int = 10, encoding: str = \"utf-8\") -> None:\n",
    "    \"\"\"Display first n lines of a file. Works with both\n",
    "    .gz and uncompressed files. Defaults to 10 lines.\n",
    "\n",
    "    :param file_path: The path to the file\n",
    "    :type file_path: PathObject\n",
    "    :param n_lines: Lines to display, defaults to 10\n",
    "    :type n_lines: int, optional\n",
    "    :param encoding: Text encoding, defaults to \"utf-8\"\n",
    "    :type encoding: str, optional\n",
    "    \"\"\"\n",
    "\n",
    "    with _open_file(file_path, encoding=encoding) as infile:\n",
    "        for line in infile:\n",
    "            if n_lines == 0:\n",
    "                break\n",
    "            try:\n",
    "                print(line.strip())\n",
    "                n_lines -= 1\n",
    "            except StopIteration:\n",
    "                return\n",
    "    return\n",
    "\n",
    "\n",
    "# Minor but I would just get rid of the width parameter if you aren't going to use it\n",
    "# I tried but wget wouldn't work without it. Haven't actually looked into it,\n",
    "# but what I *think* happens is that while the progress_bar func itself doesn't use the width param, it gets passed as a kwarg to wget where it's necessary.\n",
    "def _progress_bar(\n",
    "    current: Union[int, float], total: Union[int, float], width: int = 60\n",
    ") -> None:\n",
    "    \"\"\"Custom progress bar for wget downloads.\n",
    "\n",
    "    :param current: bytes downloaded so far\n",
    "    :type current: Union[int, float]\n",
    "    :param total: Total size of download in bytes or megabytes\n",
    "    :type total: Union[int, float]\n",
    "    :param width: Progress bar width in chars, defaults to 60\n",
    "    :type width: int, optional\n",
    "    \"\"\"\n",
    "\n",
    "    unit = \"bytes\"\n",
    "\n",
    "    # Show file size in MB for large files\n",
    "    if total >= 100000:\n",
    "        MB = 1024 * 1024\n",
    "        current = current / MB\n",
    "        total = total / MB\n",
    "        unit = \"MB\"\n",
    "\n",
    "    progress = current / total\n",
    "    progress_message = f\"Progress: \\\n",
    "    {progress:.0%} [{current:.1f} / {total:.1f}] {unit}\"\n",
    "    sys.stdout.write(\"\\r\" + progress_message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def load(database: str, filename: str, date: str = \"latest\") -> Optional[PathObject]:\n",
    "    \"\"\"Load a dump file from a Wikimedia public directory if the\n",
    "    user is in a supported environment (PAWS, Toolforge...). Otherwise, download dump file from the web and save in the current working directory. In both cases,the function returns a path-like object which can be used to access the file. Does not check if the file already exists on the path.\n",
    "\n",
    "    :param database: The database backup dump to download a file from,\n",
    "        e.g. 'enwiki' (English Wikipedia). See a list of available\n",
    "        databases here: https://dumps.wikimedia.org/backup-index-bydb.html\n",
    "    :type database: str\n",
    "    :param filename: The name of the file to download, e.g. 'page' loads the\n",
    "        file {database}-{date}-page.sql.gz\n",
    "    :type filename: str\n",
    "    :param date: Date the dump was generated, defaults to \"latest\". If \"latest\"\n",
    "        is not used, the date format should be \"YYYYMMDD\"\n",
    "    :type date: str, optional\n",
    "    :return: Path to dump file\n",
    "    :rtype: Optional[PathObject]\n",
    "    \"\"\"\n",
    "\n",
    "    # style: generally I only use ALL_CAPS variables when it's global so I would just change these to normal_var_names\n",
    "    # Oh, cool! I though all caps were for constants in general but TIL\n",
    "    # they're specifically for module level constants\n",
    "    paws_root_dir = Path(\"/public/dumps/public/\")\n",
    "    dumps_url = \"https://dumps.wikimedia.org/\"\n",
    "    subdir = Path(database, date)\n",
    "    extended_filename = f\"{database}-{date}-{filename}.sql.gz\"\n",
    "    file_path = Path(extended_filename)\n",
    "\n",
    "    if paws_root_dir.exists():\n",
    "        dump_file = Path(paws_root_dir, subdir, file_path)\n",
    "\n",
    "    else:\n",
    "        url = f\"{dumps_url}{str(subdir)}/{str(file_path)}\"\n",
    "        try:\n",
    "            print(f\"Downloading {url}\")\n",
    "            dump_file = wget.download(url, bar=_progress_bar)\n",
    "        except HTTPError:\n",
    "            print(\"File not found\")\n",
    "            return None\n",
    "\n",
    "    return Path(dump_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a950b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://dumps.wikimedia.org/simplewiki/latest/simplewiki-latest-change_tag_def.sql.gz\n",
      "Progress:     100% [2131.0 / 2131.0] bytes"
     ]
    }
   ],
   "source": [
    "f = load('simplewiki', 'change_tag_def', 'latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cef9a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f == PosixPath('simplewiki-20210701-change_tag_def.sql.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d938f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- MySQL dump 10.18  Distrib 10.3.27-MariaDB, for debian-linux-gnu (x86_64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with _open_file(f) as infile:    \n",
    "    for line in infile:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf2a6a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- MySQL dump 10.18  Distrib 10.3.27-MariaDB, for debian-linux-gnu (x86_64)\n",
      "--\n",
      "-- Host: 10.64.32.82    Database: simplewiki\n",
      "-- ------------------------------------------------------\n",
      "-- Server version\t10.4.19-MariaDB-log\n",
      "\n",
      "/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n",
      "/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n",
      "/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n",
      "/*!40101 SET NAMES utf8mb4 */;\n"
     ]
    }
   ],
   "source": [
    "head(f, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f547a532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-- MySQL dump 10.18  Distrib 10.3.27-MariaDB, for debian-linux-gnu (x86_64)',\n",
       " '--',\n",
       " '-- Host: 10.64.32.82    Database: simplewiki',\n",
       " '-- ------------------------------------------------------',\n",
       " '-- Server version\\t10.4.19-MariaDB-log',\n",
       " '',\n",
       " '/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;',\n",
       " '/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;',\n",
       " '/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;',\n",
       " '/*!40101 SET NAMES utf8mb4 */;',\n",
       " '/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;',\n",
       " \"/*!40103 SET TIME_ZONE='+00:00' */;\",\n",
       " '/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;',\n",
       " '/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;',\n",
       " \"/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\",\n",
       " '/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;',\n",
       " '',\n",
       " '--',\n",
       " '-- Table structure for table `change_tag_def`',\n",
       " '--',\n",
       " '',\n",
       " 'DROP TABLE IF EXISTS `change_tag_def`;',\n",
       " '/*!40101 SET @saved_cs_client     = @@character_set_client */;',\n",
       " '/*!40101 SET character_set_client = utf8 */;',\n",
       " 'CREATE TABLE `change_tag_def` (',\n",
       " '`ctd_id` int(10) unsigned NOT NULL AUTO_INCREMENT,',\n",
       " '`ctd_name` varbinary(255) NOT NULL,',\n",
       " '`ctd_user_defined` tinyint(1) NOT NULL,',\n",
       " '`ctd_count` bigint(20) unsigned NOT NULL DEFAULT 0,',\n",
       " 'PRIMARY KEY (`ctd_id`),',\n",
       " 'UNIQUE KEY `ctd_name` (`ctd_name`),',\n",
       " 'KEY `ctd_count` (`ctd_count`),',\n",
       " 'KEY `ctd_user_defined` (`ctd_user_defined`)',\n",
       " ') ENGINE=InnoDB AUTO_INCREMENT=126 DEFAULT CHARSET=binary;',\n",
       " '/*!40101 SET character_set_client = @saved_cs_client */;',\n",
       " '',\n",
       " '--',\n",
       " '-- Dumping data for table `change_tag_def`',\n",
       " '--',\n",
       " '',\n",
       " '/*!40000 ALTER TABLE `change_tag_def` DISABLE KEYS */;',\n",
       " \"INSERT INTO `change_tag_def` VALUES (1,'mw-replace',0,10200),(2,'visualeditor',0,305860),(3,'mw-undo',0,58220),(4,'mw-rollback',0,70687),(5,'mobile edit',0,230487),(6,'mobile web edit',0,223010),(7,'very short new article',0,28586),(8,'visualeditor-wikitext',0,20113),(9,'mw-new-redirect',0,29681),(10,'visualeditor-switched',0,17717),(11,'mw-removed-redirect',0,4426),(12,'repeating characters',0,6721),(13,'blanking',0,19912),(14,'mw-blank',0,42285),(15,'mw-changed-redirect-target',0,4539),(16,'uppercase- or lowercase-only article',0,24377),(17,'emoji',0,2054),(18,'talk page blanking',0,235),(19,'redirect page with extra text',0,675),(20,'article with links to other-language wikis?',0,3556),(21,'possible vandalism',0,4952),(22,'meta spam id',0,219),(23,'copy/paste from another Wikipedia?',0,1229),(24,'contenttranslation',0,1147),(25,'possible spamming',0,420),(26,'mobile app edit',0,6519),(27,'android app edit',0,2033),(28,'massmessage-delivery',0,3698),(36,'ios app edit',0,1023),(37,'possible libel or vandalism',0,1534),(38,'large unwikified new article',0,4066),(39,'New user creating interrogative pages',0,844),(42,'OAuth CID: 99',0,576),(43,'Possible Vandalism',0,9),(44,'Spambot edit?',0,731),(45,'Text after interwiki or categories',0,133),(46,'Text after interwiki/categories',0,283),(47,'abusefilter-condition-limit',0,127),(48,'adding email address',0,37),(50,'article with links to other-language wikis',0,4),(52,'article with uppercase title',0,520),(57,'end of page text',0,165),(58,'gettingstarted edit',0,202),(59,'goji spam test',0,1),(74,'new LGBT rights article',0,173),(75,'new tehsil article',0,83),(76,'ntsamr (global)',0,1),(77,'one-case only article',0,1481),(78,'one-case-only article',0,1779),(83,'repeated xwiki CoI abuse',0,48),(85,'reverting anti-vandal bot',0,664),(86,'short \\\\'X is a city in Y\\\\' article',0,48),(88,'test edit',0,500),(92,'visualeditor-needcheck',0,24),(93,'Possible Vandalism - LTA',1,65),(96,'mw-contentmodelchange',0,6),(97,'contenttranslation-v2',0,583),(98,'OAuth CID: 1188',0,107),(99,'Likely have problems',0,388),(101,'OAuth CID: 1261',0,160),(102,'references removed',0,4277),(103,'Spam Research',0,5),(104,'OAuth CID: 429',0,3),(105,'OAuth CID: 1352',0,5477),(106,'removal of quick deletion templates',0,1789),(107,'advanced mobile edit',0,12013),(108,'OAuth CID: 651',0,5),(109,'OAuth CID: 1805',0,2833),(110,'added links to social media sites',0,679),(111,'discussiontools',0,2832),(112,'discussiontools-reply',0,2444),(113,'discussiontools-visual',0,368),(114,'discussiontools-source',0,2464),(115,'mw-manual-revert',0,44507),(116,'T144167',0,2),(117,'mw-reverted',0,84006),(118,'Ukraine-Russia-related vandalism',0,5),(119,'new user blanking Wikipedia or WP Talk page',0,158),(120,'OAuth CID: 1804',0,99),(121,'discussiontools-newtopic',0,388),(122,'newcomer task',0,410),(123,'mw-add-media',0,23308),(124,'mw-remove-media',0,11135),(125,'discussiontools-source-enhanced',0,341);\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Capturing() as output:\n",
    "    head(f, 42)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94ae2be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: -- MySQL dump 10.18  Distrib 10.3.27-MariaDB, for debian-linux-gnu (x86_64)\n",
      "1: --\n",
      "2: -- Host: 10.64.32.82    Database: simplewiki\n",
      "3: -- ------------------------------------------------------\n",
      "4: -- Server version\t10.4.19-MariaDB-log\n",
      "5: \n",
      "6: /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n",
      "7: /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n",
      "8: /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n",
      "9: /*!40101 SET NAMES utf8mb4 */;\n",
      "10: /*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;\n",
      "11: /*!40103 SET TIME_ZONE='+00:00' */;\n",
      "12: /*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;\n",
      "13: /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n",
      "14: /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n",
      "15: /*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n",
      "16: \n",
      "17: --\n",
      "18: -- Table structure for table `change_tag_def`\n",
      "19: --\n",
      "20: \n",
      "21: DROP TABLE IF EXISTS `change_tag_def`;\n",
      "22: /*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "23: /*!40101 SET character_set_client = utf8 */;\n",
      "24: CREATE TABLE `change_tag_def` (\n",
      "25: `ctd_id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n",
      "26: `ctd_name` varbinary(255) NOT NULL,\n",
      "27: `ctd_user_defined` tinyint(1) NOT NULL,\n",
      "28: `ctd_count` bigint(20) unsigned NOT NULL DEFAULT 0,\n",
      "29: PRIMARY KEY (`ctd_id`),\n",
      "30: UNIQUE KEY `ctd_name` (`ctd_name`),\n",
      "31: KEY `ctd_count` (`ctd_count`),\n",
      "32: KEY `ctd_user_defined` (`ctd_user_defined`)\n",
      "33: ) ENGINE=InnoDB AUTO_INCREMENT=126 DEFAULT CHARSET=binary;\n",
      "34: /*!40101 SET character_set_client = @saved_cs_client */;\n",
      "35: \n",
      "36: --\n",
      "37: -- Dumping data for table `change_tag_def`\n",
      "38: --\n",
      "39: \n",
      "40: /*!40000 ALTER TABLE `change_tag_def` DISABLE KEYS */;\n",
      "41: INSERT INTO `change_tag_def` VALUES (1,'mw-replace',0,10200),(2,'visualeditor',0,305860),(3,'mw-undo',0,58220),(4,'mw-rollback',0,70687),(5,'mobile edit',0,230487),(6,'mobile web edit',0,223010),(7,'very short new article',0,28586),(8,'visualeditor-wikitext',0,20113),(9,'mw-new-redirect',0,29681),(10,'visualeditor-switched',0,17717),(11,'mw-removed-redirect',0,4426),(12,'repeating characters',0,6721),(13,'blanking',0,19912),(14,'mw-blank',0,42285),(15,'mw-changed-redirect-target',0,4539),(16,'uppercase- or lowercase-only article',0,24377),(17,'emoji',0,2054),(18,'talk page blanking',0,235),(19,'redirect page with extra text',0,675),(20,'article with links to other-language wikis?',0,3556),(21,'possible vandalism',0,4952),(22,'meta spam id',0,219),(23,'copy/paste from another Wikipedia?',0,1229),(24,'contenttranslation',0,1147),(25,'possible spamming',0,420),(26,'mobile app edit',0,6519),(27,'android app edit',0,2033),(28,'massmessage-delivery',0,3698),(36,'ios app edit',0,1023),(37,'possible libel or vandalism',0,1534),(38,'large unwikified new article',0,4066),(39,'New user creating interrogative pages',0,844),(42,'OAuth CID: 99',0,576),(43,'Possible Vandalism',0,9),(44,'Spambot edit?',0,731),(45,'Text after interwiki or categories',0,133),(46,'Text after interwiki/categories',0,283),(47,'abusefilter-condition-limit',0,127),(48,'adding email address',0,37),(50,'article with links to other-language wikis',0,4),(52,'article with uppercase title',0,520),(57,'end of page text',0,165),(58,'gettingstarted edit',0,202),(59,'goji spam test',0,1),(74,'new LGBT rights article',0,173),(75,'new tehsil article',0,83),(76,'ntsamr (global)',0,1),(77,'one-case only article',0,1481),(78,'one-case-only article',0,1779),(83,'repeated xwiki CoI abuse',0,48),(85,'reverting anti-vandal bot',0,664),(86,'short \\'X is a city in Y\\' article',0,48),(88,'test edit',0,500),(92,'visualeditor-needcheck',0,24),(93,'Possible Vandalism - LTA',1,65),(96,'mw-contentmodelchange',0,6),(97,'contenttranslation-v2',0,583),(98,'OAuth CID: 1188',0,107),(99,'Likely have problems',0,388),(101,'OAuth CID: 1261',0,160),(102,'references removed',0,4277),(103,'Spam Research',0,5),(104,'OAuth CID: 429',0,3),(105,'OAuth CID: 1352',0,5477),(106,'removal of quick deletion templates',0,1789),(107,'advanced mobile edit',0,12013),(108,'OAuth CID: 651',0,5),(109,'OAuth CID: 1805',0,2833),(110,'added links to social media sites',0,679),(111,'discussiontools',0,2832),(112,'discussiontools-reply',0,2444),(113,'discussiontools-visual',0,368),(114,'discussiontools-source',0,2464),(115,'mw-manual-revert',0,44507),(116,'T144167',0,2),(117,'mw-reverted',0,84006),(118,'Ukraine-Russia-related vandalism',0,5),(119,'new user blanking Wikipedia or WP Talk page',0,158),(120,'OAuth CID: 1804',0,99),(121,'discussiontools-newtopic',0,388),(122,'newcomer task',0,410),(123,'mw-add-media',0,23308),(124,'mw-remove-media',0,11135),(125,'discussiontools-source-enhanced',0,341);\n"
     ]
    }
   ],
   "source": [
    "d = {n: item for n, item in enumerate(output)}\n",
    "\n",
    "for n, item in enumerate(output):\n",
    "    print(f'{n}: {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2468a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ['-- MySQL dump 10.18  Distrib 10.3.27-MariaDB, for debian-linux-gnu (x86_64)',\n",
    " '--',\n",
    " '-- Host: 10.64.32.82    Database: simplewiki',\n",
    " '-- ------------------------------------------------------',\n",
    " '-- Server version\\t10.4.19-MariaDB-log',\n",
    " '',\n",
    " '/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;',\n",
    " '/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;',\n",
    " '/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;',\n",
    " '/*!40101 SET NAMES utf8mb4 */;']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4326f8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efbb0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert out == output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61cda120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parser functions used in src/dump.py\"\"\"\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "from typing import Any, Dict, Iterator, List, Optional\n",
    "\n",
    "\n",
    "def _has_sql_attribute(line: str, attr_type: str) -> bool:\n",
    "    \"\"\"Check whether a string contains a specific SQL element\n",
    "    or statement.\n",
    "\n",
    "    :param line: A line from a SQL dump file.\n",
    "    :type line: str\n",
    "    :param attr_type: Element or statement type, e.g \"primary_key\"\n",
    "        for a table's primary key or \"insert\" for INSERT INTO statements.\n",
    "    :type attr_type: str\n",
    "    :return: True or False\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "\n",
    "    # FYI: no need to update this because I think it's nice and simple but if you were trying to\n",
    "    # expand it to more use cases and finding the rules to get more complex, you would likely want to consider\n",
    "    # a regex for each like in get_sql_attribute.\n",
    "    # e.g., something like (with the caveat that I am not good at regexes): re.match('(^--).*(Database: )', line)\n",
    "    line_start = {\n",
    "        \"database\": \"--\",\n",
    "        \"insert\": \"INSERT INTO\",\n",
    "        \"create\": \"CREATE TABLE\",\n",
    "        \"primary_key\": \"PRIMARY KEY\",\n",
    "        \"col_name\": \"`\",\n",
    "    }\n",
    "    contains_element = line.strip().startswith(line_start[attr_type])\n",
    "\n",
    "    if attr_type == \"database\":\n",
    "        return contains_element and \"Database: \" in line\n",
    "\n",
    "    return contains_element\n",
    "\n",
    "\n",
    "def _get_sql_attribute(line: str, attr_type: str) -> Any:\n",
    "    \"\"\"Extract a SQL attribute from a string that contains it.\n",
    "\n",
    "    :param line: A line from a SQL dump file.\n",
    "    :type line: str\n",
    "    :param attr_type: Element or statement type, e.g \"primary_key\"\n",
    "        for a table's primary key or \"col_name\" for a column (field) name.\n",
    "    :type attr_type: str\n",
    "    :return: A SQL attribute such as database(name), table name,\n",
    "        primary_key, etc.\n",
    "    :rtype: Optional[str]\n",
    "    \"\"\"\n",
    "\n",
    "    attr_pattern = {\n",
    "        \"table_name\": r\"`([\\S]*)`\",\n",
    "        \"col_name\": r\"`([\\S]*)`\",\n",
    "        \"dtype\": r\"` ((.)*),\",\n",
    "        \"primary_key\": r\"`([\\S]*)`\",\n",
    "    }\n",
    "\n",
    "    attr: Optional[str] = None\n",
    "\n",
    "    try:\n",
    "        if attr_type == \"database\":\n",
    "            attr = line.strip().partition(\"Database: \")[-1]\n",
    "\n",
    "        elif attr_type in (\"table_name\", \"col_name\", \"dtype\"):\n",
    "            # ignore type - mypy does not understand try... except here\n",
    "            attr = re.search(attr_pattern[attr_type], line).group(1)  # type: ignore\n",
    "\n",
    "        elif attr_type == \"primary_key\":\n",
    "            attr = (\n",
    "                re.search(attr_pattern[attr_type], line)\n",
    "                .group(1)  # type: ignore\n",
    "                .replace(\"`\", \"\")\n",
    "                .split(\",\")\n",
    "            )\n",
    "\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "    # probably define attr as None before the try clause. right now if not of the if-else clauses matched, would throw a weird error\n",
    "    # Done!\n",
    "    return attr\n",
    "\n",
    "\n",
    "# I don't know much about the intricacies of types but I like this -- good and simple!\n",
    "def _map_dtypes(sql_dtypes: Dict[str, str]) -> Dict[str, type]:\n",
    "    \"\"\"Create mapping from SQL data types to Python data types.\n",
    "\n",
    "    :param sql_dtypes: A mapping from the column names in a SQL table\n",
    "        to their respective SQL data types.\n",
    "        Example: {\"ct_id\": int(10) unsigned NOT NULL AUTO_INCREMENT}\n",
    "    :type sql_dtypes: Dict[str, str]\n",
    "    :return: A mapping from the column names in a SQL table\n",
    "        to their respective Python data types. Example: {\"ct_id\": int}\n",
    "    :rtype: Dict[str, type]\n",
    "    \"\"\"\n",
    "\n",
    "    types: Dict[str, type] = {}\n",
    "    for key, val in sql_dtypes.items():\n",
    "        if \"int\" in val:\n",
    "            types[key] = int\n",
    "        elif any(dtype in val for dtype in (\"float\", \"double\", \"decimal\", \"numeric\")):\n",
    "            types[key] = float\n",
    "        else:\n",
    "            types[key] = str\n",
    "    return types\n",
    "\n",
    "\n",
    "def _convert(values: List[str], dtypes: List[type], strict: bool = False) -> List[Any]:\n",
    "    \"\"\"Cast numerical values in a list of strings to float or int\n",
    "    as specified by the dtypes parameter.\n",
    "\n",
    "    :param values: A list of strings representing a row in a SQL table\n",
    "        E.g. ['28207', 'April', '4742783', '0.9793'].\n",
    "    :type values: List[str]\n",
    "    :param dtypes: A list of Python data types. E.g. [int, str, int, float]\n",
    "    :type dtypes: List[type]\n",
    "    :param strict: When set to False, if any of the items in the list\n",
    "        cannot be converted, it is returned unchanged, i.e. as a str.\n",
    "    :type strict: bool, optional\n",
    "    :raises ValueError: If `values` is not the same length as `dtypes`,\n",
    "        or if `strict` is set to True and some of the values in the\n",
    "        list couldn't be converted.\n",
    "    :return: A list where the numerical values have been cast as int\n",
    "        or string as defined by `dtypes`. E.g. the example list from\n",
    "        above is returned as [28207, 'April', 4742783, 0.9793]\n",
    "    :rtype: List[Any]\n",
    "    \"\"\"\n",
    "\n",
    "    len_values = len(values)\n",
    "    len_dtypes = len(dtypes)\n",
    "\n",
    "    warn = False\n",
    "\n",
    "    if len_values != len_dtypes:\n",
    "        if not strict:\n",
    "            return values\n",
    "\n",
    "        raise ValueError(\"values and dtypes are not the same length\")\n",
    "\n",
    "    converted = []\n",
    "    for i in range(len_dtypes):\n",
    "        dtype = dtypes[i]\n",
    "        val = values[i]\n",
    "\n",
    "        try:\n",
    "            conv = dtype(val)\n",
    "            converted.append(conv)\n",
    "\n",
    "        except ValueError as e:\n",
    "            if values[i] == \"\":\n",
    "                # why not convert to None?\n",
    "                converted.append(val)\n",
    "            elif not strict:\n",
    "                warn = True\n",
    "                converted.append(val)\n",
    "            else:\n",
    "                # my PyCharm installation doesn't like this and things it won't work FYI. I haven't tested it though.\n",
    "                # You're right - I've changed this now.\n",
    "                print(f\"ValueError: {e}\")\n",
    "\n",
    "    if warn:\n",
    "        # low priority: perhaps include the values too? or problematic value?\n",
    "        # > I need to think about how to handle this because some files, notably\n",
    "        # externallinks, have > 10^3 such values\n",
    "        warnings.warn(\"some rows could not be converted to Python dtypes\")\n",
    "\n",
    "    return converted\n",
    "\n",
    "\n",
    "def _split_tuples(line: str) -> List[str]:\n",
    "    \"\"\"Split an INSERT INTO statement into a list of strings each\n",
    "    representing a SQL table row.\n",
    "\n",
    "    :param line: An INSERT INTO statement, e.g. \"INSERT INTO `change_tag_def`\n",
    "        VALUES (1,'mw-replace',0,10200),(2,'visualeditor',0,305860);\"\n",
    "    :type line: str\n",
    "    :return: A list with items representing SQL rows,\n",
    "        e.g. [\"1,'mw-replace',0,10200\", \"2,'visualeditor',0,305860\"]\n",
    "    :rtype: List[str]\n",
    "    \"\"\"\n",
    "\n",
    "    # I think the NULL replacement might need some tweaking. The challenge is two-fold:\n",
    "    # * making NULL into something that doesn't break the parser -- that's easy, either add quotes like you do or replace with None\n",
    "    # > I have opted for replacing NULL with the empty string when it's used\n",
    "    # to denote missing values (i.e. not part of some other string). The reason\n",
    "    # is that `None` is somewhat specific to pure Python while Pandas, Numpy, R, CSV, and others recognize the empty string as a missing value and sub it with their own null equivalent (NaN, NA, <na>, ...)\n",
    "    # * not making this replacement when e.g., NULL is just part of a real value like a page title as happens in Commons sometimes\n",
    "    # For the latter, I think you might need to a regex that only does the replacement when it sees any of the following\n",
    "    # which in theory should capture all the ways that NULL shows up as a full field value:\n",
    "    # * ,NULL,\n",
    "    # * (NULL,\n",
    "    # * ,NULL)\n",
    "    # > Good suggestion - I have implemented this regex.\n",
    "    tuples = line.partition(\" VALUES \")[-1].strip()\n",
    "    # Sub NULL with the empty string\n",
    "    pattern = r\"(?<=[,(])NULL(?=[,)])\"\n",
    "    values = re.sub(pattern, \"\", tuples)\n",
    "    # Remove `;` at the end of the last `INSERT INTO` statement\n",
    "    if values[-1] == \";\":\n",
    "        values = values[:-1]\n",
    "    records = re.split(r\"\\),\\(\", values[1:-1])  # Strip `(` and `)`\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def _parse(\n",
    "    line: str,\n",
    "    delimiter: str = \",\",\n",
    "    escape_char: str = \"\\\\\",\n",
    "    quote_char: str = \"'\",\n",
    "    doublequote: bool = False,\n",
    "    strict: bool = True,\n",
    ") -> Iterator[List[str]]:\n",
    "    \"\"\"Parse an INSERT INTO statement and return a generator that yields from a list of CSV-formatted strings, each representing a SQL table row. This\n",
    "    is essentially a wrapper around a csv.reader object and takes the same\n",
    "    parameters, except it takes a string as input instead of an iterator-type\n",
    "    object.\n",
    "\n",
    "    :param line: An INSERT INTO statement, e.g. \"INSERT INTO `change_tag_def`\n",
    "        VALUES (1,'mw-replace',0,10200),(2,'visualeditor',0,305860);\"\n",
    "    :type line: str\n",
    "    :param delimiter: A one-character string used to separate fields,\n",
    "        defaults to \",\"\n",
    "    :type delimiter: str, optional\n",
    "    :param escape_char: A one-character string used by the reader to remove\n",
    "        any special meaning from the following character, defaults to \"\\\"\n",
    "    :type escape_char: str, optional\n",
    "    :param quote_char: A one-character string used to quote fields\n",
    "        containing special characters, such as the delimiter or quotechar,\n",
    "        or which contain new-line characters, defaults to \"'\"\n",
    "    :type quote_char: str, optional\n",
    "    :param doublequote: Controls how instances of quotechar appearing inside\n",
    "        a field should themselves be quoted. When True, the character\n",
    "        is doubled. When False, the escapechar is used as a prefix\n",
    "        to the quotechar. Defaults to False.\n",
    "    :type doublequote: bool, optional\n",
    "    :param strict: When True, raise exception Error on bad CSV input.\n",
    "        Defaults to True.\n",
    "    :type strict: bool, optional\n",
    "    :return: A generator that yields from a list of CSV-formatted strings.\n",
    "    :rtype: Iterator[List[str]]\n",
    "    \"\"\"\n",
    "\n",
    "    records = _split_tuples(line)\n",
    "    reader = csv.reader(\n",
    "        records,\n",
    "        delimiter=delimiter,\n",
    "        escapechar=escape_char,\n",
    "        quotechar=quote_char,\n",
    "        doublequote=doublequote,\n",
    "        strict=strict,\n",
    "    )\n",
    "    return reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7145e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ctd_name'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_sql_attribute(output[26], 'col_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9f51e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '-- MySQL dump 10.18  Distrib 10.3.27-MariaDB, for debian-linux-gnu (x86_64)',\n",
       " 1: '--',\n",
       " 2: '-- Host: 10.64.32.82    Database: simplewiki',\n",
       " 3: '-- ------------------------------------------------------',\n",
       " 4: '-- Server version\\t10.4.19-MariaDB-log',\n",
       " 5: '',\n",
       " 6: '/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;',\n",
       " 7: '/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;',\n",
       " 8: '/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;',\n",
       " 9: '/*!40101 SET NAMES utf8mb4 */;',\n",
       " 10: '/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;',\n",
       " 11: \"/*!40103 SET TIME_ZONE='+00:00' */;\",\n",
       " 12: '/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;',\n",
       " 13: '/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;',\n",
       " 14: \"/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\",\n",
       " 15: '/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;',\n",
       " 16: '',\n",
       " 17: '--',\n",
       " 18: '-- Table structure for table `change_tag_def`',\n",
       " 19: '--',\n",
       " 20: '',\n",
       " 21: 'DROP TABLE IF EXISTS `change_tag_def`;',\n",
       " 22: '/*!40101 SET @saved_cs_client     = @@character_set_client */;',\n",
       " 23: '/*!40101 SET character_set_client = utf8 */;',\n",
       " 24: 'CREATE TABLE `change_tag_def` (',\n",
       " 25: '`ctd_id` int(10) unsigned NOT NULL AUTO_INCREMENT,',\n",
       " 26: '`ctd_name` varbinary(255) NOT NULL,',\n",
       " 27: '`ctd_user_defined` tinyint(1) NOT NULL,',\n",
       " 28: '`ctd_count` bigint(20) unsigned NOT NULL DEFAULT 0,',\n",
       " 29: 'PRIMARY KEY (`ctd_id`),',\n",
       " 30: 'UNIQUE KEY `ctd_name` (`ctd_name`),',\n",
       " 31: 'KEY `ctd_count` (`ctd_count`),',\n",
       " 32: 'KEY `ctd_user_defined` (`ctd_user_defined`)',\n",
       " 33: ') ENGINE=InnoDB AUTO_INCREMENT=126 DEFAULT CHARSET=binary;',\n",
       " 34: '/*!40101 SET character_set_client = @saved_cs_client */;',\n",
       " 35: '',\n",
       " 36: '--',\n",
       " 37: '-- Dumping data for table `change_tag_def`',\n",
       " 38: '--',\n",
       " 39: '',\n",
       " 40: '/*!40000 ALTER TABLE `change_tag_def` DISABLE KEYS */;',\n",
       " 41: \"INSERT INTO `change_tag_def` VALUES (1,'mw-replace',0,10200),(2,'visualeditor',0,305860),(3,'mw-undo',0,58220),(4,'mw-rollback',0,70687),(5,'mobile edit',0,230487),(6,'mobile web edit',0,223010),(7,'very short new article',0,28586),(8,'visualeditor-wikitext',0,20113),(9,'mw-new-redirect',0,29681),(10,'visualeditor-switched',0,17717),(11,'mw-removed-redirect',0,4426),(12,'repeating characters',0,6721),(13,'blanking',0,19912),(14,'mw-blank',0,42285),(15,'mw-changed-redirect-target',0,4539),(16,'uppercase- or lowercase-only article',0,24377),(17,'emoji',0,2054),(18,'talk page blanking',0,235),(19,'redirect page with extra text',0,675),(20,'article with links to other-language wikis?',0,3556),(21,'possible vandalism',0,4952),(22,'meta spam id',0,219),(23,'copy/paste from another Wikipedia?',0,1229),(24,'contenttranslation',0,1147),(25,'possible spamming',0,420),(26,'mobile app edit',0,6519),(27,'android app edit',0,2033),(28,'massmessage-delivery',0,3698),(36,'ios app edit',0,1023),(37,'possible libel or vandalism',0,1534),(38,'large unwikified new article',0,4066),(39,'New user creating interrogative pages',0,844),(42,'OAuth CID: 99',0,576),(43,'Possible Vandalism',0,9),(44,'Spambot edit?',0,731),(45,'Text after interwiki or categories',0,133),(46,'Text after interwiki/categories',0,283),(47,'abusefilter-condition-limit',0,127),(48,'adding email address',0,37),(50,'article with links to other-language wikis',0,4),(52,'article with uppercase title',0,520),(57,'end of page text',0,165),(58,'gettingstarted edit',0,202),(59,'goji spam test',0,1),(74,'new LGBT rights article',0,173),(75,'new tehsil article',0,83),(76,'ntsamr (global)',0,1),(77,'one-case only article',0,1481),(78,'one-case-only article',0,1779),(83,'repeated xwiki CoI abuse',0,48),(85,'reverting anti-vandal bot',0,664),(86,'short \\\\'X is a city in Y\\\\' article',0,48),(88,'test edit',0,500),(92,'visualeditor-needcheck',0,24),(93,'Possible Vandalism - LTA',1,65),(96,'mw-contentmodelchange',0,6),(97,'contenttranslation-v2',0,583),(98,'OAuth CID: 1188',0,107),(99,'Likely have problems',0,388),(101,'OAuth CID: 1261',0,160),(102,'references removed',0,4277),(103,'Spam Research',0,5),(104,'OAuth CID: 429',0,3),(105,'OAuth CID: 1352',0,5477),(106,'removal of quick deletion templates',0,1789),(107,'advanced mobile edit',0,12013),(108,'OAuth CID: 651',0,5),(109,'OAuth CID: 1805',0,2833),(110,'added links to social media sites',0,679),(111,'discussiontools',0,2832),(112,'discussiontools-reply',0,2444),(113,'discussiontools-visual',0,368),(114,'discussiontools-source',0,2464),(115,'mw-manual-revert',0,44507),(116,'T144167',0,2),(117,'mw-reverted',0,84006),(118,'Ukraine-Russia-related vandalism',0,5),(119,'new user blanking Wikipedia or WP Talk page',0,158),(120,'OAuth CID: 1804',0,99),(121,'discussiontools-newtopic',0,388),(122,'newcomer task',0,410),(123,'mw-add-media',0,23308),(124,'mw-remove-media',0,11135),(125,'discussiontools-source-enhanced',0,341);\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97120998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility functions used to download, open and display\n",
    " the contents of Wikimedia SQL dump files.\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from typing import Iterator, Optional, TextIO, Union\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import wget  # type: ignore\n",
    "\n",
    "# Custom type\n",
    "PathObject = Union[str, Path]\n",
    "\n",
    "\n",
    "# TODO: eventually will want to update the function calls to match rest of library -- e.g., file_path: string, mode: string, etc.\n",
    "# Done!\n",
    "@contextmanager\n",
    "def _open_file(\n",
    "    file_path: PathObject, encoding: Optional[str] = None\n",
    ") -> Iterator[TextIO]:\n",
    "    \"\"\"Custom context manager for opening both .gz and uncompressed files.\n",
    "\n",
    "    :param file_path: The path to the file\n",
    "    :type file_path: PathObject\n",
    "    :param encoding: Text encoding, defaults to None\n",
    "    :type encoding: Optional[str], optional\n",
    "    :yield: A file handle\n",
    "    :rtype: Iterator[TextIO]\n",
    "    \"\"\"\n",
    "\n",
    "    if str(file_path).endswith(\".gz\"):\n",
    "        infile = gzip.open(file_path, mode=\"rt\", encoding=encoding)\n",
    "    else:\n",
    "        infile = open(file_path, mode=\"r\", encoding=encoding)\n",
    "    try:\n",
    "        yield infile\n",
    "    finally:\n",
    "        infile.close()\n",
    "\n",
    "\n",
    "def head(file_path: PathObject, n_lines: int = 10, encoding: str = \"utf-8\") -> None:\n",
    "    \"\"\"Display first n lines of a file. Works with both\n",
    "    .gz and uncompressed files. Defaults to 10 lines.\n",
    "\n",
    "    :param file_path: The path to the file\n",
    "    :type file_path: PathObject\n",
    "    :param n_lines: Lines to display, defaults to 10\n",
    "    :type n_lines: int, optional\n",
    "    :param encoding: Text encoding, defaults to \"utf-8\"\n",
    "    :type encoding: str, optional\n",
    "    \"\"\"\n",
    "\n",
    "    with _open_file(file_path, encoding=encoding) as infile:\n",
    "        for line in infile:\n",
    "            if n_lines == 0:\n",
    "                break\n",
    "            try:\n",
    "                print(line.strip())\n",
    "                n_lines -= 1\n",
    "            except StopIteration:\n",
    "                return\n",
    "    return\n",
    "\n",
    "\n",
    "# Minor but I would just get rid of the width parameter if you aren't going to use it\n",
    "# I tried but wget wouldn't work without it. Haven't actually looked into it,\n",
    "# but what I *think* happens is that while the progress_bar func itself doesn't use the width param, it gets passed as a kwarg to wget where it's necessary.\n",
    "def _progress_bar(\n",
    "    current: Union[int, float], total: Union[int, float], width: int = 60\n",
    ") -> None:\n",
    "    \"\"\"Custom progress bar for wget downloads.\n",
    "\n",
    "    :param current: bytes downloaded so far\n",
    "    :type current: Union[int, float]\n",
    "    :param total: Total size of download in bytes or megabytes\n",
    "    :type total: Union[int, float]\n",
    "    :param width: Progress bar width in chars, defaults to 60\n",
    "    :type width: int, optional\n",
    "    \"\"\"\n",
    "\n",
    "    unit = \"bytes\"\n",
    "\n",
    "    # Show file size in MB for large files\n",
    "    if total >= 100000:\n",
    "        MB = 1024 * 1024\n",
    "        current = current / MB\n",
    "        total = total / MB\n",
    "        unit = \"MB\"\n",
    "\n",
    "    progress = current / total\n",
    "    progress_message = f\"Progress: \\\n",
    "    {progress:.0%} [{current:.1f} / {total:.1f}] {unit}\"\n",
    "    sys.stdout.write(\"\\r\" + progress_message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def load(database: str, filename: str, date: str = \"latest\") -> Optional[PathObject]:\n",
    "    \"\"\"Load a dump file from a Wikimedia public directory if the\n",
    "    user is in a supported environment (PAWS, Toolforge...). Otherwise, download dump file from the web and save in the current working directory. In both cases,the function returns a path-like object which can be used to access the file. Does not check if the file already exists on the path.\n",
    "\n",
    "    :param database: The database backup dump to download a file from,\n",
    "        e.g. 'enwiki' (English Wikipedia). See a list of available\n",
    "        databases here: https://dumps.wikimedia.org/backup-index-bydb.html\n",
    "    :type database: str\n",
    "    :param filename: The name of the file to download, e.g. 'page' loads the\n",
    "        file {database}-{date}-page.sql.gz\n",
    "    :type filename: str\n",
    "    :param date: Date the dump was generated, defaults to \"latest\". If \"latest\"\n",
    "        is not used, the date format should be \"YYYYMMDD\"\n",
    "    :type date: str, optional\n",
    "    :return: Path to dump file\n",
    "    :rtype: Optional[PathObject]\n",
    "    \"\"\"\n",
    "\n",
    "    # style: generally I only use ALL_CAPS variables when it's global so I would just change these to normal_var_names\n",
    "    # Oh, cool! I though all caps were for constants in general but TIL\n",
    "    # they're specifically for module level constants\n",
    "    paws_root_dir = Path(\"/public/dumps/public/\")\n",
    "    dumps_url = \"https://dumps.wikimedia.org/\"\n",
    "    subdir = Path(database, date)\n",
    "    extended_filename = f\"{database}-{date}-{filename}.sql.gz\"\n",
    "    file_path = Path(extended_filename)\n",
    "\n",
    "    if paws_root_dir.exists():\n",
    "        dump_file = Path(paws_root_dir, subdir, file_path)\n",
    "\n",
    "    else:\n",
    "        url = f\"{dumps_url}{str(subdir)}/{str(file_path)}\"\n",
    "        try:\n",
    "            print(f\"Downloading {url}\")\n",
    "            dump_file = wget.download(url, bar=_progress_bar)\n",
    "        except HTTPError:\n",
    "            print(\"File not found\")\n",
    "            return None\n",
    "\n",
    "    return Path(dump_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d5b0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A set of utilities for processing MediaWiki SQL dump data\"\"\"\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterator, List, Optional, Type, TypeVar, Union\n",
    "\n",
    "# from .parser import (\n",
    "#     _convert,\n",
    "#     _get_sql_attribute,\n",
    "#     _has_sql_attribute,\n",
    "#     _map_dtypes,\n",
    "#     _parse,\n",
    "# )\n",
    "# from .utils import _open_file\n",
    "\n",
    "# Allow long field names\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# Custom types\n",
    "PathObject = Union[str, Path]\n",
    "T = TypeVar(\"T\", bound=\"Dump\")\n",
    "\n",
    "\n",
    "class Dump:\n",
    "    \"\"\"Class for parsing an SQL dump file and processing its contents\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        database: Optional[str],\n",
    "        table_name: Optional[str],\n",
    "        col_names: List[str],\n",
    "        col_sql_dtypes: Dict[str, str],\n",
    "        primary_key: Optional[str],\n",
    "        source_file: PathObject,\n",
    "        encoding: str,\n",
    "    ) -> None:\n",
    "        \"\"\"Dump class constructor.\n",
    "\n",
    "        :param database: The wiki database, e.g. 'enwiki' or 'dewikibooks'\n",
    "        :type database: Optional[str]\n",
    "        :param table_name: The SQL table name\n",
    "        :type table_name: Optional[str]\n",
    "        :param col_names: The SQL table column (field) names\n",
    "        :type col_names: List[str]\n",
    "        :param col_sql_dtypes: A mapping from the column names in a SQL table\n",
    "            to their respective SQL data types.\n",
    "            Example: {\"ct_id\": int(10) unsigned NOT NULL AUTO_INCREMENT}\n",
    "        :type col_sql_dtypes: Dict[str, str]\n",
    "        :param primary_key: The primary key of the SQL table\n",
    "            Can be unique or composite.\n",
    "        :type primary_key: Optional[str]\n",
    "        :param source_file: The path to the SQL dump file\n",
    "        :type source_file: PathObject\n",
    "        :param encoding: Text encoding\n",
    "        :type encoding: str\n",
    "        \"\"\"\n",
    "\n",
    "        self.db = database\n",
    "        self.name = table_name\n",
    "        self.col_names = col_names\n",
    "        self.sql_dtypes = col_sql_dtypes\n",
    "        self.primary_key = primary_key\n",
    "        self.size = Path(source_file).stat().st_size\n",
    "        self._dtypes: Optional[Dict[str, type]] = None\n",
    "        self._source_file = source_file\n",
    "        self._encoding = encoding\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"Dump(database={self.db}, name={self.name}, size={self.size})\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)\n",
    "\n",
    "    def __iter__(self) -> Iterator[List[Any]]:\n",
    "        return self.rows()\n",
    "\n",
    "    @property\n",
    "    def encoding(self) -> str:\n",
    "        \"\"\"Get the encoding used to read the dump file.\n",
    "\n",
    "        :return: Text encoding\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "\n",
    "        return self._encoding\n",
    "\n",
    "    @encoding.setter\n",
    "    def encoding(self, new_encoding: str) -> None:\n",
    "        \"\"\"Set the encoding used to read the dump file.\n",
    "\n",
    "        :param new_encoding: Text encoding\n",
    "        :type new_encoding: str\n",
    "        \"\"\"\n",
    "\n",
    "        self._encoding = new_encoding\n",
    "\n",
    "    @property\n",
    "    def dtypes(self) -> Dict[str, type]:\n",
    "        \"\"\"Mapping between col_names and native Python dtypes.\n",
    "\n",
    "        :return: A mapping from the column names in a SQL table\n",
    "        to their respective Python data types. Example: {\"ct_id\": int}\n",
    "        :rtype: Dict[str, type]\n",
    "        \"\"\"\n",
    "\n",
    "        if self._dtypes is None:\n",
    "            self._dtypes = _map_dtypes(self.sql_dtypes)\n",
    "        return self._dtypes\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls: Type[T], file_path: PathObject, encoding: str = \"utf-8\") -> T:\n",
    "        \"\"\"Initialize Dump object from dump file.\n",
    "\n",
    "        :param cls: A Dump class instance\n",
    "        :type cls: Dump\n",
    "        :param file_path: Path to source SQL dum file. Can be a .gz or an\n",
    "            uncompressed file\n",
    "        :type file_path: PathObject\n",
    "        :param encoding: Text encoding, defaults to \"utf-8\" If you get\n",
    "        an encoding error when processing the file, try setting this\n",
    "            parameter to 'Latin-1'\n",
    "        :type encoding: str, optional\n",
    "        :return: A Dump class instance\n",
    "        :rtype: Dump\n",
    "        \"\"\"\n",
    "\n",
    "        source_file = file_path\n",
    "        database = None\n",
    "        table_name = None\n",
    "        primary_key = None\n",
    "        col_names = []\n",
    "        col_sql_dtypes = {}\n",
    "\n",
    "        # Extract meta data from dump file\n",
    "        with _open_file(file_path, encoding=encoding) as infile:\n",
    "            for line in infile:\n",
    "                if _has_sql_attribute(line, \"database\"):\n",
    "                    database = _get_sql_attribute(line, \"database\")\n",
    "\n",
    "                elif _has_sql_attribute(line, \"create\"):\n",
    "                    table_name = _get_sql_attribute(line, \"table_name\")\n",
    "\n",
    "                elif _has_sql_attribute(line, \"col_name\"):\n",
    "                    col_name = _get_sql_attribute(line, \"col_name\")\n",
    "                    dtype = _get_sql_attribute(line, \"dtype\")\n",
    "                    col_names.append(col_name)\n",
    "                    col_sql_dtypes[col_name] = dtype\n",
    "\n",
    "                elif _has_sql_attribute(line, \"primary_key\"):\n",
    "                    primary_key = _get_sql_attribute(line, \"primary_key\")\n",
    "\n",
    "                elif _has_sql_attribute(line, \"insert\"):\n",
    "                    break\n",
    "\n",
    "            return cls(\n",
    "                database,\n",
    "                table_name,\n",
    "                col_names,  # type: ignore\n",
    "                col_sql_dtypes,  # type: ignore\n",
    "                primary_key,\n",
    "                source_file,\n",
    "                encoding,\n",
    "            )\n",
    "\n",
    "    def rows(\n",
    "        self,\n",
    "        convert_dtypes: bool = False,\n",
    "        strict_conversion: bool = False,\n",
    "        **fmtparams: Any,\n",
    "    ) -> Iterator[List[Any]]:\n",
    "        \"\"\"Create a generator object from the rows.\n",
    "\n",
    "        :param convert_dtypes: When set to True, numerical types are\n",
    "            converted from str to int or float. Defaults to False.\n",
    "        :type convert_dtypes: bool, optional\n",
    "        :param strict_conversion: When True, raise exception Error on\n",
    "            bad input when converting from SQL dtypes to Python dtypes.\n",
    "            Defaults to False.\n",
    "        :type strict_conversion: bool, optional\n",
    "        :param fmtparams: Any kwargs you want to pass to the csv.reader()\n",
    "            function that does the actual parsing.\n",
    "        :yield: A generator used to iterate over the rows in the SQL table\n",
    "        :rtype: Iterator[List[Any]]\n",
    "        \"\"\"\n",
    "\n",
    "        if convert_dtypes:\n",
    "            dtypes = list(self.dtypes.values())\n",
    "\n",
    "        with _open_file(self._source_file, encoding=self.encoding) as infile:\n",
    "            for line in infile:\n",
    "                if _has_sql_attribute(line, \"insert\"):\n",
    "                    rows = _parse(line, **fmtparams)\n",
    "                    for row in rows:\n",
    "                        if convert_dtypes:\n",
    "                            converted_row = _convert(\n",
    "                                row, dtypes, strict=strict_conversion\n",
    "                            )\n",
    "                            yield converted_row\n",
    "                        else:\n",
    "                            yield row\n",
    "\n",
    "    def to_csv(self, file_path: PathObject, **fmtparams: Any) -> None:\n",
    "        \"\"\"Write Dump object to CSV file.\n",
    "\n",
    "        :param file_path: The file to write to. Will be created if it\n",
    "            doesn't already exist. Will be overwritten if it does exist.\n",
    "        :type file_path: PathObject\n",
    "        \"\"\"\n",
    "\n",
    "        with open(file_path, \"w\") as outfile:\n",
    "            writer = csv.writer(outfile, **fmtparams)\n",
    "            writer.writerow(self.col_names)\n",
    "            for row in self:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    def head(self, n_lines: int = 10, convert_dtypes: bool = False) -> None:\n",
    "        \"\"\"Display first n rows.\n",
    "\n",
    "        :param n_lines: Number of rows to display, defaults to 10\n",
    "        :type n_lines: int, optional\n",
    "        :param convert_dtypes: Optionally, shows numerical types as int\n",
    "            or float instead of all str. Defaults to False.\n",
    "        :type convert_dtypes: bool, optional\n",
    "        \"\"\"\n",
    "\n",
    "        rows = self.rows(convert_dtypes=convert_dtypes)\n",
    "        print(self.col_names)\n",
    "\n",
    "        for _ in range(n_lines):\n",
    "            try:\n",
    "                print(next(rows))\n",
    "            except StopIteration:\n",
    "                return\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14e260e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capture.ipynb\r\n",
      "capture.py\r\n",
      "simplewiki-latest-change_tag_def.sql (1).gz\r\n",
      "simplewiki-latest-change_tag_def.sql.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0be41087",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dump.from_file('simplewiki-latest-change_tag_def.sql.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2708818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctd_id': int, 'ctd_name': str, 'ctd_user_defined': int, 'ctd_count': int}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "556e7667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctd_id': 'int(10) unsigned NOT NULL AUTO_INCREMENT',\n",
       " 'ctd_name': 'varbinary(255) NOT NULL',\n",
       " 'ctd_user_defined': 'tinyint(1) NOT NULL',\n",
       " 'ctd_count': 'bigint(20) unsigned NOT NULL DEFAULT 0'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sql_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9ac52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mwsql",
   "language": "python",
   "name": "mwsql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
